# KNN Optimization ‚Äî KD-Tree ‡¶ì Ball Tree: In-Depth ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ Intuition

---

## üî¥ ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ: ‡¶ï‡ßá‡¶® KNN slow?

Normal (Brute Force) KNN ‡¶è:

- ‡¶®‡¶§‡ßÅ‡¶® point ‡¶è‡¶≤‡ßá
- ‡¶∏‡¶¨ training point‚Äì‡¶è‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá distance ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨ ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡ßü

‚è±Ô∏è Time Complexity:

$$
\mathcal{O}(n \times d)
$$

üß† Intuition:

> ‚Äú‡¶è‡¶ï‡¶ú‡¶® ‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑‡¶ï‡ßá ‡¶ñ‡ßÅ‡¶Å‡¶ú‡¶§‡ßá ‡¶™‡ßÅ‡¶∞‡ßã ‡¶ó‡ßç‡¶∞‡¶æ‡¶Æ ‡¶ò‡ßÅ‡¶∞‡ßá ‡¶¶‡ßá‡¶ñ‡¶æ‚Äù

‚û°Ô∏è Solution: **Smart data structure ‡¶¶‡¶ø‡ßü‡ßá search fast ‡¶ï‡¶∞‡¶æ**

---

## üü¢ KD-Tree (K-Dimensional Tree)

### 1Ô∏è‚É£ KD-Tree ‡¶ï‡ßÄ?

**KD-Tree ‡¶π‡¶≤‡ßã space-partitioning data structure** ‚Äî feature space ‡¶ï‡ßá ‡¶¨‡¶æ‡¶∞‡¶¨‡¶æ‡¶∞ **axis ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡ßá** ‡¶è‡¶ï‡¶ü‡¶æ **binary tree** ‡¶¨‡¶æ‡¶®‡¶æ‡ßü‡•§

### 2Ô∏è‚É£ Core Intuition (‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£)

> ‚Äú‡¶™‡ßÅ‡¶∞‡ßã ‡¶ú‡¶æ‡ßü‡¶ó‡¶æ‡¶ü‡¶æ ‡¶Ü‡¶ó‡ßá ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡ßá ‡¶´‡ßá‡¶≤‡¶ø, ‡¶§‡¶æ‡¶∞‡¶™‡¶∞ ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞‡¶ø ‡¶ú‡¶æ‡ßü‡¶ó‡¶æ‡ßü ‡¶ñ‡ßÅ‡¶Å‡¶ú‡¶ø‚Äù

### 3Ô∏è‚É£ 2D Example ‡¶¶‡¶ø‡ßü‡ßá Intuition

‡¶ß‡¶∞‡¶ø data point ‡¶ó‡ßÅ‡¶≤‡ßã \((x, y)\) plane-‡¶è ‡¶Ü‡¶õ‡ßá‡•§

**Step 1Ô∏è‚É£: Root node (x-axis ‡¶¶‡¶ø‡ßü‡ßá split)**

- \(x\) ‡¶è‡¶∞ median ‡¶®‡¶ø‡¶á
- ‡¶¨‡¶æ‡¶Æ ‡¶™‡¶æ‡¶∂‡ßá ‚Üí \(x\) ‡¶õ‡ßã‡¶ü
- ‡¶°‡¶æ‡¶® ‡¶™‡¶æ‡¶∂‡ßá ‚Üí \(x\) ‡¶¨‡ßú

‚úÇÔ∏è Vertical cut

**Step 2Ô∏è‚É£: Next level (y-axis ‡¶¶‡¶ø‡ßü‡ßá split)**

- ‡¶è‡¶¨‡¶æ‡¶∞ \(y\) ‡¶è‡¶∞ median
- ‡¶â‡¶™‡¶∞‚Äì‡¶®‡¶ø‡¶ö ‡¶≠‡¶æ‡¶ó

‚úÇÔ∏è Horizontal cut

**Step 3Ô∏è‚É£: Alternate split**

- \(x \to y \to x \to y \dots\)

üß† Intuition:

> ‚Äú‡¶è‡¶ï‡¶¨‡¶æ‡¶∞ ‡¶≤‡¶Æ‡ßç‡¶¨‡¶æ ‡¶ï‡ßá‡¶ü‡ßá, ‡¶è‡¶ï‡¶¨‡¶æ‡¶∞ ‡¶Ü‡ßú‡¶æ‡¶Ü‡ßú‡¶ø ‡¶ï‡ßá‡¶ü‡ßá ‡¶ú‡¶Æ‡¶ø ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡¶æ‚Äù

### 4Ô∏è‚É£ Search ‡¶ï‡¶∞‡¶æ‡¶∞ Intuition (KNN)

‡¶ß‡¶∞‡¶ø query point \(Q\) ‡¶è‡¶∏‡ßá‡¶õ‡ßá‡•§

**Step 1Ô∏è‚É£: Tree ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶®‡¶ø‡¶ö‡ßá ‡¶®‡¶æ‡¶Æ‡¶ø** ‚Äî ‡¶ï‡ßã‡¶® side-‡¶è ‡¶™‡ßú‡¶õ‡ßá ‚Üí ‡¶∏‡ßá‡¶á branch ‡¶è ‡¶Ø‡¶æ‡¶á‡•§

**Step 2Ô∏è‚É£: Leaf ‡¶è ‡¶™‡ßå‡¶Å‡¶õ‡ßá nearest candidate ‡¶®‡¶ø‡¶á**

**Step 3Ô∏è‚É£: Backtracking (‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£!)**

- ‡¶Ö‡¶®‡ßç‡¶Ø branch-‡¶è closer point ‡¶•‡¶æ‡¶ï‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá ‡¶ï‡¶ø ‡¶®‡¶æ check
- ‡¶Ø‡¶¶‡¶ø **splitting plane distance < current best distance** ‚Üí ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶∏‡ßá‡¶á branch-‡¶è‡¶ì ‡¶Ø‡¶æ‡¶á

üß† Intuition:

> ‚Äú‡¶™‡¶æ‡¶∂‡ßá‡¶∞ ‡¶∞‡¶æ‡¶∏‡ßç‡¶§‡¶æ‡ßü ‡¶è‡¶ï‡¶ü‡ßÅ ‡¶ò‡ßÅ‡¶∞‡ßá ‡¶¶‡ßá‡¶ñ‡¶≤‡ßá ‡¶π‡ßü‡¶§‡ßã ‡¶ï‡¶æ‡¶õ‡ßá‡¶∞ ‡¶¶‡ßã‡¶ï‡¶æ‡¶® ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶Ø‡¶æ‡¶¨‡ßá‚Äù

### 5Ô∏è‚É£ KD-Tree ‡¶ï‡¶¨‡ßá ‡¶≠‡¶æ‡¶≤‡ßã ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡ßá?

‚úÖ Dimension ‡¶ï‡¶Æ (\(d \le 10\)‚Äì20)

‚úÖ Data evenly distributed

‚ùå High dimension ‡¶π‡¶≤‡ßá performance ‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™

### 6Ô∏è‚É£ KD-Tree Complexity

- Build: \(\mathcal{O}(n \log n)\)
- Query (avg): \(\mathcal{O}(\log n)\)
- Worst: \(\mathcal{O}(n)\) (high dimension)

---

## üîµ Ball Tree

### 1Ô∏è‚É£ Ball Tree ‡¶ï‡ßÄ?

**Ball Tree data ‡¶ï‡ßá sphere (ball) ‡¶Ü‡¶ï‡¶æ‡¶∞‡ßá ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡ßá** ‚Äî axis ‡¶¶‡¶ø‡ßü‡ßá ‡¶®‡ßü, **distance** ‡¶¶‡¶ø‡ßü‡ßá‡•§

### 2Ô∏è‚É£ Core Intuition

> ‚Äú‡¶ö‡¶æ‡¶∞‡¶ï‡ßã‡¶£‡¶æ ‡¶≠‡¶æ‡¶ó ‡¶®‡¶æ ‡¶ï‡¶∞‡ßá ‡¶ó‡ßã‡¶≤ ‡¶¨‡¶≤ ‡¶¨‡¶æ‡¶®‡¶æ‡¶á‚Äù

### 3Ô∏è‚É£ Ball Tree ‡¶ï‡¶ø‡¶≠‡¶æ‡¶¨‡ßá ‡¶¨‡¶æ‡¶®‡¶æ‡¶®‡ßã ‡¶π‡ßü?

**Step 1Ô∏è‚É£: ‡¶∏‡¶¨ data ‡¶®‡¶ø‡ßü‡ßá ‡¶è‡¶ï‡¶ü‡¶æ ‡¶¨‡ßú ball** ‚Äî Center = mean, Radius = farthest point‡•§

**Step 2Ô∏è‚É£: Data ‡¶ï‡ßá ‡¶¶‡ßÅ‡¶á ‡¶≠‡¶æ‡¶ó‡ßá split** ‚Äî ‡¶¶‡ßÅ‡¶á‡¶ü‡¶æ ‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶¶‡ßÇ‡¶∞‡ßá‡¶∞ point ‡¶ß‡¶∞‡¶ø; ‡¶¨‡¶æ‡¶ï‡¶ø ‡¶™‡ßü‡ßá‡¶®‡ßç‡¶ü‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Ø‡ßá‡¶ü‡¶æ‡¶∞ ‡¶¨‡ßá‡¶∂‡¶ø ‡¶ï‡¶æ‡¶õ‡ßá ‚Üí ‡¶∏‡ßá‡¶á group‡•§

**Step 3Ô∏è‚É£: Recursively smaller balls** ‚Äî ‡¶¨‡ßú ball ‡¶è‡¶∞ ‡¶≠‡¶ø‡¶§‡¶∞ ‡¶õ‡ßã‡¶ü ‡¶õ‡ßã‡¶ü ball‡•§

üß† Intuition:

> ‚Äú‡¶è‡¶ï‡¶ü‡¶æ ‡¶¨‡ßú ‡¶¨‡ßá‡¶≤‡ßÅ‡¶® ‚Üí ‡¶õ‡ßã‡¶ü ‡¶õ‡ßã‡¶ü ‡¶¨‡ßá‡¶≤‡ßÅ‡¶®‡ßá ‡¶≠‡¶æ‡¶ó‚Äù

### 4Ô∏è‚É£ Search Intuition (‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£)

Query point \(Q\) ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø:

**Step 1Ô∏è‚É£: Ball distance check**

$$
	ext{lowerBound}(Q, \text{ball}) = \operatorname{dist}(Q, \text{center}) - \text{radius}
$$

- ‡¶Ø‡¶¶‡¶ø ‡¶è‡¶á ‡¶Æ‡¶æ‡¶® \(>\) current best distance ‚Üí ‡¶™‡ßÅ‡¶∞‡ßã ball ‡¶¨‡¶æ‡¶¶‡•§

**Step 2Ô∏è‚É£: Closer ball ‡¶Ü‡¶ó‡ßá search** ‚Äî ‡¶Ø‡ßá‡¶ü‡¶æ ‡¶ï‡¶æ‡¶õ‡ßá ‚Üí ‡¶Ü‡¶ó‡ßá; ‡¶¶‡ßÇ‡¶∞‡ßá‡¶∞‡¶ü‡¶æ ‡¶™‡¶∞‡ßá / skip‡•§

üß† Intuition:

> ‚Äú‡¶è‡¶á ‡¶ó‡ßã‡¶≤ ‡¶ú‡¶æ‡ßü‡¶ó‡¶æ‡¶∞ ‡¶≠‡ßá‡¶§‡¶∞‡ßá ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶õ‡ßá‡¶∞ ‡¶ï‡ßá‡¶â ‡¶®‡ßá‡¶á, ‡¶¢‡ßÅ‡¶ï‡¶¨‡ßã ‡¶®‡¶æ‚Äù

### 5Ô∏è‚É£ Ball Tree ‡¶ï‡¶¨‡ßá ‡¶≠‡¶æ‡¶≤‡ßã?

‚úÖ High dimensional data

‚úÖ Distance metric complex (cosine, haversine)

‚ùå Low dimension ‡¶π‡¶≤‡ßá KD-Tree faster

### 6Ô∏è‚É£ Ball Tree Complexity

- Build: \(\mathcal{O}(n \log n)\)
- Query: pruning-‡¶è‡¶∞ ‡¶â‡¶™‡¶∞ ‡¶®‡¶ø‡¶∞‡ßç‡¶≠‡¶∞ ‡¶ï‡¶∞‡ßá
- High-D ‡¶§‡ßá KD-Tree ‡¶è‡¶∞ ‡¶ö‡ßá‡ßü‡ßá ‡¶≠‡¶æ‡¶≤‡ßã ‡¶π‡¶ì‡ßü‡¶æ‡¶∞ ‡¶∏‡¶Æ‡ßç‡¶≠‡¶æ‡¶¨‡¶®‡¶æ ‡¶¨‡ßá‡¶∂‡¶ø

---

## üî• KD-Tree vs Ball Tree (Deep Comparison)

| ‡¶¨‡¶ø‡¶∑‡ßü         | KD-Tree          | Ball Tree       |
| ------------ | ---------------- | --------------- |
| Partition    | Axis-aligned     | Distance-based  |
| Shape        | Rectangle        | Sphere          |
| Split        | x, y, z          | Center + radius |
| Best for     | Low dimension    | High dimension  |
| Metric       | Mostly Euclidean | Any metric      |
| Curse of Dim | Yes              | Less impact     |

---

## üéØ Brute Force vs Tree (Intuition)

| Method      | Intuition            |
| ----------- | -------------------- |
| Brute Force | ‡¶™‡ßÅ‡¶∞‡ßã ‡¶∂‡¶π‡¶∞ ‡¶ñ‡ßã‡¶Å‡¶ú‡¶æ       |
| KD-Tree     | ‡¶∞‡¶æ‡¶∏‡ßç‡¶§‡¶æ ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡ßá ‡¶ñ‡ßã‡¶Å‡¶ú‡¶æ |
| Ball Tree   | ‡¶è‡¶≤‡¶æ‡¶ï‡¶æ ‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶ø‡ßü‡ßá ‡¶ñ‡ßã‡¶Å‡¶ú‡¶æ |

---

## üß† One-line Intuition

- **KD-Tree** ‚Üí ‚Äú‡¶¶‡¶ø‡¶ï ‡¶ß‡¶∞‡ßá ‡¶ú‡¶æ‡ßü‡¶ó‡¶æ ‡¶≠‡¶æ‡¶ó‚Äù
- **Ball Tree** ‚Üí ‚Äú‡¶¶‡ßÇ‡¶∞‡¶§‡ßç‡¶¨ ‡¶ß‡¶∞‡ßá ‡¶è‡¶≤‡¶æ‡¶ï‡¶æ ‡¶¨‡¶æ‡¶¶‚Äù

---

## üìå ‡¶¨‡¶æ‡¶∏‡ßç‡¶§‡¶¨‡ßá (scikit-learn)

```python
from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(
	n_neighbors=5,
	algorithm="kd_tree"  # ‡¶¨‡¶æ "ball_tree" / "brute" / "auto"
)
knn.fit(X_train, y_train)
pred = knn.predict(X_test)
```

### üîé `algorithm="auto"` ‡¶π‡¶≤‡ßá ‡¶ï‡ßÄ ‡¶π‡ßü?

- sklearn **metric** (‡¶Ø‡ßá‡¶Æ‡¶® Euclidean/Minkowski) ‡¶ì **dimension/distribution** ‡¶¶‡ßá‡¶ñ‡ßá ‡¶Ö‡¶≠‡ßç‡¶Ø‡¶®‡ßç‡¶§‡¶∞‡ßÄ‡¶£‡¶≠‡¶æ‡¶¨‡ßá `kd_tree`, `ball_tree` ‡¶¨‡¶æ `brute` ‡¶¨‡ßá‡¶õ‡ßá ‡¶®‡ßá‡ßü‡•§
- Unsupported metric ‡¶¨‡¶æ ‡¶ñ‡ßÅ‡¶¨ high-D ‡¶π‡¶≤‡ßá **brute** fallback ‡¶¶‡ßá‡¶ñ‡¶æ ‡¶Ø‡¶æ‡ßü‡•§
- ‡¶õ‡ßã‡¶ü dataset-‡¶è brute ‡¶Ö‡¶®‡ßá‡¶ï ‡¶∏‡¶Æ‡ßü ‡¶Ø‡¶•‡ßá‡¶∑‡ßç‡¶ü ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§‡•§

### üìé NearestNeighbors ‡¶¶‡¶ø‡ßü‡ßá pure search

```python
from sklearn.neighbors import NearestNeighbors

nn = NearestNeighbors(n_neighbors=5, algorithm="ball_tree", metric="euclidean")
nn.fit(X)
dist, idx = nn.kneighbors(Q)  # Q: query points
```

---

## üß™ Bonus: KD vs Ball vs Brute ‚Äî ‡¶õ‡ßã‡¶ü ‡¶¨‡ßá‡¶û‡ßç‡¶ö‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï

‡¶è‡¶ï‡¶á data-‡¶§‡ßá ‡¶§‡¶ø‡¶®‡¶ü‡¶ø algorithm ‡¶ö‡¶æ‡¶≤‡¶ø‡ßü‡ßá **fit/query time** ‡¶§‡ßÅ‡¶≤‡¶®‡¶æ ‡¶ï‡¶∞‡¶≤‡ßá ‡¶ß‡¶æ‡¶∞‡¶£‡¶æ ‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü ‡¶π‡ßü‡•§

- ‡¶ï‡¶Æ dimension ‚Üí KD-Tree ‡¶∏‡ßÅ‡¶¨‡¶ø‡¶ß‡¶æ
- ‡¶¨‡ßá‡¶∂‡¶ø dimension/complex metric ‚Üí Ball Tree ‡¶¨‡¶æ brute ‡¶≠‡¶æ‡¶≤‡ßã ‡¶π‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá

‡¶¨‡ßá‡¶û‡ßç‡¶ö‡¶Æ‡¶æ‡¶∞‡ßç‡¶ï ‡¶∞‡¶æ‡¶® ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡¶ø‡¶™‡ßç‡¶ü: ‡¶¶‡ßá‡¶ñ‡ßã [code/knn_tree_benchmark.py](code/knn_tree_benchmark.py)

Quick run (Windows PowerShell):

```powershell
python -m pip install -r requirements.txt
python code/knn_tree_benchmark.py --dims 5 20 50 --samples 3000 --queries 100 --k 5 --metric euclidean
```

