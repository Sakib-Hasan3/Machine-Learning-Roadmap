

---

# üîç **Performance Metrics ‡¶ï‡ßÄ?**

Performance Metrics ‡¶π‡¶≤‡ßã ‡¶è‡¶Æ‡¶® ‡¶∏‡¶¨ ‡¶™‡¶∞‡¶ø‡¶Æ‡¶æ‡¶™‡¶ï ‡¶Æ‡¶æ‡¶®, ‡¶Ø‡¶æ ‡¶¶‡¶ø‡ßü‡ßá ‡¶Ü‡¶Æ‡¶∞‡¶æ Machine Learning ‡¶Æ‡¶°‡ßá‡¶≤‡ßá‡¶∞ **‡¶ï‡ßã‡¶®‡¶ü‡¶æ ‡¶≠‡¶æ‡¶≤‡ßã, ‡¶ï‡ßã‡¶®‡¶ü‡¶æ ‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™**‚Äî‡¶§‡¶æ ‡¶™‡¶∞‡¶ø‡¶Æ‡¶æ‡¶™ ‡¶ï‡¶∞‡¶ø‡•§

* Classification ‚Üí Accuracy, Precision, Recall, F1, ROC-AUC
* Regression ‚Üí MSE, RMSE, MAE, R¬≤ Score
* Imbalanced data ‚Üí Precision-Recall, F1, AUC-PR

---

![Image](https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg?utm_source=chatgpt.com)

![Image](https://ashutoshtripathicom.files.wordpress.com/2022/01/precision-recall-vs-roc-auc.png?w=840&utm_source=chatgpt.com)

---

# üü¶ **A. Classification Metrics (Binary + Multi-Class)**

## 1Ô∏è‚É£ **Confusion Matrix** (‡¶Æ‡ßÇ‡¶≤ ‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø)

```
								Predicted
							| 1      | 0
Actual   1    | TP     | FN
				 0    | FP     | TN
```

* **TP** = True Positive
* **TN** = True Negative
* **FP** = False Positive
* **FN** = False Negative

---

## 2Ô∏è‚É£ **Accuracy**

[
Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
]

‡¶ï‡¶¨‡ßá ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá‡¶® ‚Üí ‡¶Ø‡¶ñ‡¶® dataset **balanced** ‡¶•‡¶æ‡¶ï‡ßá‡•§

Limit ‚Üí imbalanced dataset-‡¶è ‡¶≠‡ßÅ‡¶≤ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ ‡¶¶‡ßá‡ßü‡•§

---

## 3Ô∏è‚É£ **Precision**

[
Precision = \frac{TP}{TP + FP}
]

"Predicted positives ‡¶è‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶ï‡¶§‡¶ó‡ßÅ‡¶≤‡ßã ‡¶∏‡¶§‡ßç‡¶Ø‡¶ø?"

‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£: Spam detection ‚Üí spam ‡¶¨‡¶≤‡¶≤‡ßá ‡¶∏‡¶§‡ßç‡¶Ø‡¶ø‡¶á spam ‡¶ï‡¶ø‡¶®‡¶æ?

---

## 4Ô∏è‚É£ **Recall (Sensitivity / TPR)**

[
Recall = \frac{TP}{TP + FN}
]

"Actual positives ‡¶ï‡¶§‡¶ü‡ßÅ‡¶ï‡ßÅ detect ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶õ‡ßá?"

‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£: Disease detection ‚Üí ‡¶Ö‡¶∏‡ßÅ‡¶∏‡ßç‡¶• ‡¶∞‡ßã‡¶ó‡ßÄ ‡¶¨‡¶æ‡¶¶ ‡¶™‡ßú‡¶≤‡ßá ‡¶¨‡ßú ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ‡•§

---

## 5Ô∏è‚É£ **F1-Score (Harmonic Mean)**

[
F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}
]

Precision ‡¶ì Recall-‡¶è‡¶∞ balanced score ‚Üí imbalanced dataset-‡¶è ‡¶Ö‡¶§‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£‡•§

---

## 6Ô∏è‚É£ **Specificity (TNR)**

[
Specificity = \frac{TN}{TN + FP}
]

True negative portion‡•§

---

## 7Ô∏è‚É£ **ROC Curve ‡¶è‡¶¨‡¶Ç AUC**

* ROC ‚Üí TPR vs FPR curve
* AUC ‚Üí Area Under Curve = Model-‡¶è‡¶∞ ‡¶∂‡¶ï‡ßç‡¶§‡¶ø

[
AUC = 0.5 \Rightarrow Random
AUC = 1.0 \Rightarrow Perfect model
]

Balanced dataset-‡¶è ‡¶ñ‡ßÅ‡¶¨ ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£‡•§

---

## 8Ô∏è‚É£ **Precision-Recall Curve (AUC-PR)**

Imbalanced dataset-‡¶è ROC curve ‡¶¨‡¶ø‡¶≠‡ßç‡¶∞‡¶æ‡¶®‡ßç‡¶§ ‡¶ï‡¶∞‡ßá, PR curve ‡¶¨‡ßá‡¶∂‡¶ø informative‡•§

---

## 9Ô∏è‚É£ **Log Loss (Cross Entropy Loss)**

[
Loss = -[y\log(p) + (1-y)\log(1-p)]
]

Probabilistic classifier (logistic, softmax)-‡¶è‡¶∞ official scoring metric‡•§

---

---

# üü© **B. Multi-Class Classification Metrics**

## 1Ô∏è‚É£ **Macro / Micro / Weighted Averages**

* **Macro F1** ‚Üí ‡¶∏‡¶¨ ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡¶ï‡ßá ‡¶∏‡¶Æ‡¶æ‡¶® ‡¶ì‡¶ú‡¶®
* **Micro F1** ‚Üí overall TP/FP/FN
* **Weighted F1** ‚Üí ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶∏‡¶æ‡¶á‡¶ú ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶ì‡¶ú‡¶®

---

## 2Ô∏è‚É£ **Top-K Accuracy**

‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£: Image classification (ImageNet)

Model top-k prediction-‡¶è‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶∏‡¶†‡¶ø‡¶ï ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ ‡¶•‡¶æ‡¶ï‡¶≤‡ßá ‡¶∏‡¶´‡¶≤‡•§

---

---

# üü• **C. Regression Metrics**

![Image](https://www.researchgate.net/publication/362260849/figure/tbl1/AS%3A1184487119552531%401659415144265/Values-of-MSE-RMSE-MAE-MAPE-and-R-2-for-the-eight-models.png?utm_source=chatgpt.com)

![Image](https://miro.medium.com/v2/resize%3Afit%3A1358/1%2A5fnmYVHLTC8mGxybHm4XkA.png?utm_source=chatgpt.com)

## 1Ô∏è‚É£ **MSE (Mean Squared Error)**

[
MSE = \frac{1}{n}\sum (y - \hat{y})^2
]

Errors ‚Üí square ‚Üí large error ‡¶¨‡ßá‡¶∂‡¶ø penalize ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡•§

---

## 2Ô∏è‚É£ **RMSE (Root Mean Squared Error)**

[
RMSE = \sqrt{MSE}
]

Interpretation ‡¶∏‡¶π‡¶ú (same unit as target variable)‡•§

---

## 3Ô∏è‚É£ **MAE (Mean Absolute Error)**

[
MAE = \frac{1}{n}\sum |y - \hat{y}|
]

Outlier-‡¶è stable (better than MSE)‡•§

---

## 4Ô∏è‚É£ **R¬≤ Score (Coefficient of Determination)**

[
R^2 = 1 - \frac{SS_{res}}{SS_{tot}}
]

* R¬≤ = 1 ‚Üí perfect
* R¬≤ = 0 ‚Üí ‡¶ñ‡ßÅ‡¶¨ ‡¶ñ‡¶æ‡¶∞‡¶æ‡¶™
* R¬≤ negative ‡¶π‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá ‚Üí model total ‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶•

---

## 5Ô∏è‚É£ **Adjusted R¬≤**

Multiple features ‡¶•‡¶æ‡¶ï‡¶≤‡ßá ‡¶¨‡ßá‡¶∂‡¶ø informative‡•§
Penalty ‡¶¶‡ßá‡ßü ‚Äî useless features ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶≤‡ßá‡¶á score ‡¶®‡¶æ ‡¶¨‡¶æ‡ßú‡ßá‡•§

---

---

# üüß **D. Clustering Metrics (Unsupervised)**

## 1Ô∏è‚É£ **Silhouette Score**

[
(-1 \text{ to } 1)
]

Higher ‚Üí clusters far & clean‡•§

## 2Ô∏è‚É£ **Davies‚ÄìBouldin Index**

Lower ‚Üí better clustering‡•§

## 3Ô∏è‚É£ **Calinski‚ÄìHarabasz Index**

Higher ‚Üí better separation‡•§

---

---

# üü¶ ‡¶ï‡¶ñ‡¶® ‡¶ï‡ßã‡¶® ‡¶Æ‡ßá‡¶ü‡ßç‡¶∞‡¶ø‡¶ï ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá‡¶®?

| Problem Type                   | Best Metrics                  |
| ------------------------------ | ----------------------------- |
| Balanced Binary Classification | Accuracy, ROC-AUC             |
| Imbalanced Classification      | F1, Precision, Recall, AUC-PR |
| Medical diagnosis              | Recall, F1                    |
| Fraud detection                | Precision, Recall, AUC-PR     |
| Regression                     | RMSE, MAE, R¬≤                 |
| Clustering                     | Silhouette, DBI               |

---

