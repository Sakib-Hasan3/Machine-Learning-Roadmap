
# ЁЯОп **Logistic Regression тАФ OVR (One Vs Rest) ржХрзА?**

ржпржЦржи Logistic Regression ржжрж┐рзЯрзЗ **multi-class classification** ржХрж░рждрзЗ рж╣рзЯ (ржпрзЗржоржи: 3 ржмрж╛ рждрж╛рж░ ржмрзЗрж╢рж┐ ржХрзНрж▓рж╛рж╕), рждржЦржи рж╕ржмржЪрзЗрзЯрзЗ ржЬржиржкрзНрж░рж┐рзЯ ржкржжрзНржзрждрж┐ рж╣рж▓рзЛ **OVR**ред

OVR = ржкрзНрж░рждрж┐ржЯрж┐ ржХрзНрж▓рж╛рж╕рзЗрж░ ржЬржирзНржп ржЖрж▓рж╛ржжрж╛ ржХрж░рзЗ Binary Logistic Regression ржоржбрзЗрж▓ рждрзИрж░рж┐ ржХрж░рж╛ред


![Image](https://media.geeksforgeeks.org/wp-content/uploads/20230330170812/Screenshot-2023-03-30-170740.png?utm_source=chatgpt.com)

![Image](https://miro.medium.com/v2/resize%3Afit%3A788/1%2Au9Kj9xXuGXiu8RJqwCGtig.png?utm_source=chatgpt.com)

---

# ЁЯза **ржорзВрж▓ ржзрж╛рж░ржгрж╛**

ржпржжрж┐ ржЖржорж╛ржжрзЗрж░ ржХрж╛ржЫрзЗ 3ржЯрж┐ ржХрзНрж▓рж╛рж╕ ржерж╛ржХрзЗ:
**A, B, C**

рждрж╛рж╣рж▓рзЗ Logistic Regression ржжрж┐рзЯрзЗ multi-class ржХрж░рж╛рж░ ржЙржкрж╛рзЯ:

### ЁЯСЙ A class ржЖрж▓рж╛ржжрж╛ ржХрж░рзЗ:

A vs (B, C)

### ЁЯСЙ B class ржЖрж▓рж╛ржжрж╛ ржХрж░рзЗ:

B vs (A, C)

### ЁЯСЙ C class ржЖрж▓рж╛ржжрж╛ ржХрж░рзЗ:

C vs (A, B)

тЮб ржорзЛржЯ рзйржЯрж┐ logistic regression model
тЮб Each model тЖТ 1 probability output ржжрзЗржпрж╝
тЮб Highest probability тЖТ final predicted class

---

# ЁЯзк **ржЧрж╛ржгрж┐рждрж┐ржХ ржмрзНржпрж╛ржЦрзНржпрж╛ (Math Intuition)**

ржкрзНрж░рждрж┐ржЯрж┐ ржХрзНрж▓рж╛рж╕рзЗрж░ ржЬржирзНржп Binary Logistic Model:

[
P(y=k|x) = \sigma(w_k^T x + b_k)
]

Prediction rule:

[
\hat{y} = \arg\max_k P(y=k|x)
]

ржЕрж░рзНржерж╛рзОтАФржпрзЗ ржХрзНрж▓рж╛рж╕рзЗрж░ probability рж╕ржмржЪрзЗржпрж╝рзЗ ржмрзЗрж╢рж┐ тЖТ рж╕рзЗржЯрж╛ржЗ predictionред

---

# ЁЯФе **Example (Bangla Intuition)**

ржПржХржЯрж┐ ржлрж▓ detect ржХрж░рждрзЗ рж╣ржмрзЗ:

ржХрзНрж▓рж╛рж╕ = {Apple, Mango, Banana}

ржоржбрзЗрж▓ 3ржЯрж┐ probability ржжрж┐рж▓тАФ

* P(Apple) = 0.18
* P(Mango) = 0.72
* P(Banana) = 0.10

тЮб Prediction = **Mango**

---

# ЁЯФН OVR vs Softmax (Multinomial Logistic)

| ржмрж┐рж╖рзЯ        | OVR (One vs Rest)           | Softmax (Multinomial) |
| ----------- | --------------------------- | --------------------- |
| Model       | K binary models             | One model             |
| Probability | Independent                 | Sum = 1               |
| Faster?     | тЬФ Fast                      | тЭМ Slower              |
| Accuracy    | Good                        | Better                |
| Use Case    | High-dim sparse data (text) | Normal data           |

Softmax mathematically superior,
OVR computationally simplerред

---

# ЁЯЯй **Python Implementation тАФ OVR Logistic Regression**

Sklearn default ржнрж╛ржмрзЗ ржЕржирзЗржХ solver-ржП **OVR** ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗред

```python
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import load_iris

X, y = load_iris(return_X_y=True)

model = LogisticRegression(multi_class='ovr', solver='liblinear')
model.fit(X, y)

print("Prediction:", model.predict([[5.1, 3.5, 1.4, 0.2]]))
print("Class probabilities:", model.predict_proba([[5.1, 3.5, 1.4, 0.2]]))
```

---

# ЁЯЯж **OVR ржПрж░ рж╕рзБржмрж┐ржзрж╛**

тЬФ Implement ржХрж░рж╛ рж╕рж╣ржЬ
тЬФ Train ржХрж░рж╛ ржжрзНрж░рзБржд
тЬФ Model interpret ржХрж░рж╛ рж╕рж╣ржЬ
тЬФ High-dimensional data (text classification)-ржП ржЦрзБржм ржХрж╛рж░рзНржпржХрж░
тЬФ Debugging рж╕рж╣ржЬ (ржХрзЛржи ржХрзНрж▓рж╛рж╕рзЗ ржнрзБрж▓ рж╣ржЪрзНржЫрзЗ ржмрзЛржЭрж╛ ржпрж╛рзЯ)

---

# ЁЯЯе **OVR ржПрж░ рж╕рзАржорж╛ржмржжрзНржзрждрж╛**

тЭМ Probabilities sum-to-one ржирзЯ
тЭМ Some decision boundary overlap рж╣рждрзЗ ржкрж╛рж░рзЗ
тЭМ Multinomial softmax-ржПрж░ рждрзБрж▓ржирж╛рзЯ ржХржЦржирзЛ accuracy ржХржо рж╣рждрзЗ ржкрж╛рж░рзЗ
тЭМ K models = computational cost grows linearly

---

# ЁЯза **Short Notes (Exam-friendly)**

* OVR = Each class vs All Others
* K classes тЖТ K binary logistic regression models
* Prediction = class with highest probability
* Faster than softmax but less mathematically elegant
* Useful in high-dimensional sparse data (NLP/text classification)

---




