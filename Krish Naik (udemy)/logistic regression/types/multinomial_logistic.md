‡¶®‡ßÄ‡¶ö‡ßá **Multinomial Logistic Regression**‚Äì‡¶è‡¶∞ ‡¶∏‡¶π‡¶ú ‡¶ì ‡¶™‡¶∞‡¶ø‡¶∑‡ßç‡¶ï‡¶æ‡¶∞ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ **‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶≠‡¶æ‡¶∑‡¶æ‡ßü** ‡¶¶‡ßá‡¶ì‡ßü‡¶æ ‡¶π‡¶≤‡ßã‚Äî

---

# üéØ Multinomial Logistic Regression ‡¶ï‡ßÄ?

**Multinomial Logistic Regression** ‡¶π‡¶≤‡ßã Logistic Regression-‡¶è‡¶∞ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ß‡¶∞‡¶®, ‡¶Ø‡¶æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü ‡¶Ø‡¶ñ‡¶® ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶¨‡¶æ ‡¶ü‡¶æ‡¶∞‡ßç‡¶ó‡ßá‡¶ü **‡¶¶‡ßÅ‡¶á‡¶ü‡¶ø‡¶∞ ‡¶¨‡ßá‡¶∂‡¶ø ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏** ‡¶•‡¶æ‡¶ï‡ßá‡•§

‡¶Ö‡¶∞‡ßç‡¶•‡¶æ‡ßé, ‡¶è‡¶ü‡¶ø ‡¶è‡¶ï‡¶ü‡¶ø **multi-class classification** ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶≤‡¶ó‡¶∞‡¶ø‡¶¶‡¶Æ‡•§

### ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£:

* ‡¶´‡¶≤‡ßá‡¶∞ ‡¶ß‡¶∞‡¶® ‚Üí **Apple / Mango / Banana**
* ‡¶õ‡¶æ‡¶§‡ßç‡¶∞‡¶¶‡ßá‡¶∞ ‡¶ó‡ßç‡¶∞‡ßá‡¶° ‚Üí **A / B / C / D**
* ‡¶™‡ßç‡¶∞‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶ß‡¶∞‡¶® ‚Üí **Cat / Dog / Horse**
* ‡¶´‡ßÅ‡¶≤‡ßá‡¶∞ ‡¶ß‡¶∞‡¶® ‚Üí **Setosa / Versicolor / Virginica** (Iris dataset)

---

![Image](https://i.ytimg.com/vi/L0FU8NFpx4E/hqdefault.jpg?utm_source=chatgpt.com)

![Image](https://cdn.sanity.io/images/vr8gru94/production/582a6c51701bb584c1cdd6662cc376b9cadb7160-2048x1152.png?utm_source=chatgpt.com)

---

# ‚≠ê Multinomial Logistic Regression ‡¶ï‡ßÄ‡¶≠‡¶æ‡¶¨‡ßá ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡ßá?

Binary Logistic Regression-‡¶è Sigmoid ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶π‡ßü‡•§
‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ Multinomial Logistic Regression-‡¶è ‡¶Ü‡¶Æ‡¶∞‡¶æ **Softmax Function** ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶ø‡•§

---

# 1Ô∏è‚É£ Step ‚Äî Linear Combination (‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø)

‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ï‡¶∞‡ßá score ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü:

[
z_k = w_kx + b_k
]

‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá
(k) = ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡ßá‡¶∞ ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞
‡¶Æ‡ßã‡¶ü ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏ = (K)

---

# 2Ô∏è‚É£ Step ‚Äî Softmax Function ‡¶¶‡¶ø‡ßü‡ßá Probability ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ

Softmax ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡ßá‡¶∞ score-‡¶ï‡ßá probability-‡¶§‡ßá ‡¶∞‡ßÇ‡¶™‡¶æ‡¶®‡ßç‡¶§‡¶∞ ‡¶ï‡¶∞‡ßá:

[
P(y=k|x) = \frac{e^{z_k}}{\sum_{j=1}^{K} e^{z_j}}
]

‡¶è‡¶á‡¶≠‡¶æ‡¶¨‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡ßá‡¶∞ probability-‡¶è‡¶∞ ‡¶Ø‡ßã‡¶ó‡¶´‡¶≤ = **1** ‡¶π‡ßü‡•§

---

# 3Ô∏è‚É£ Step ‚Äî Prediction (Highest Probability Class)

```
‡¶Ø‡ßá ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡ßá‡¶∞ probability ‡¶¨‡ßá‡¶∂‡¶ø ‚Üí ‡¶∏‡ßá‡¶ü‡¶æ‡¶á predicted class
```

‡¶Ø‡ßá‡¶Æ‡¶®:
P(Apple)=0.10
P(Banana)=0.25
P(Mango)=0.65 ‚Üí Predicted: **Mango**

---

# üìå Cost Function ‚Äî Multiclass Cross Entropy

[
Cost = -\sum_{k=1}^{K} y_k \log(P(y=k|x))
]

---

# ‚≠ê Multinomial Logistic Regression ‡¶ï‡ßã‡¶•‡¶æ‡ßü ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶π‡ßü?

* NLP ‚Üí Sentiment: Positive / Negative / Neutral
* Image Classification (dog/cat/bird)
* Handwritten digit recognition (0‚Äì9)
* Medical diagnosis ‚Äî ‡¶∞‡ßã‡¶ó ‡ßß/‡ß®/‡ß©
* Recommendation systems

---

# ‚≠ê Multinomial vs Binary Logistic Regression (‡¶§‡ßÅ‡¶≤‡¶®‡¶æ)

| ‡¶¨‡¶ø‡¶∑‡ßü          | Binary Logistic Regression | Multinomial Logistic Regression |
| ------------- | -------------------------- | ------------------------------- |
| ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏  | 2 ‡¶ü‡¶æ                       | 3 ‡¶¨‡¶æ ‡¶§‡¶§‡ßã‡¶ß‡¶ø‡¶ï                     |
| Activation    | Sigmoid                    | Softmax                         |
| Cost Function | Binary Cross Entropy       | Multiclass Cross Entropy        |
| ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£        | Pass/Fail                  | A/B/C/D Grade                   |

---

# üìå Python Code Example (Multinomial Logistic Regression)

```python
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import load_iris

# Dataset load
X, y = load_iris(return_X_y=True)

model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=200)
model.fit(X, y)

prediction = model.predict([[5.2, 3.4, 1.5, 0.2]])
print(prediction)   # ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£: [0], [1] ‡¶¨‡¶æ [2]
```

---

# üîç ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡¶π‡¶ú ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£ (Bangla)

‡¶ß‡¶∞‡ßÅ‡¶®, ‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ ‡¶ï‡¶æ‡¶ú ‡¶π‡¶≤‡ßã ‡¶è‡¶ï‡¶ü‡¶ø ‡¶´‡¶≤‡ßá‡¶∞ ‡¶õ‡¶¨‡¶ø ‡¶¶‡ßá‡¶ñ‡ßá ‡¶¨‡¶≤‡¶§‡ßá ‡¶π‡¶¨‡ßá ‡¶è‡¶ü‡¶ø‚Äî

* Apple
* Mango
* Banana

Model ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶≤:

* P(Apple) = 0.12
* P(Mango) = 0.71
* P(Banana) = 0.17

‡¶§‡¶æ‡¶π‡¶≤‡ßá **Prediction: Mango**

---

‡¶Ü‡¶™‡¶®‡¶ø ‡¶ö‡¶æ‡¶á‡¶≤‡ßá ‡¶Ü‡¶Æ‡¶ø ‡¶è‡¶ü‡¶ø ‡¶Ü‡¶∞‡¶ì ‡¶ó‡¶≠‡ßÄ‡¶∞‡¶≠‡¶æ‡¶¨‡ßá ‡¶¨‡ßã‡¶ù‡¶æ‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø ‡¶Ø‡ßá‡¶Æ‡¶®:
‚úî Softmax-‡¶è‡¶∞ ‡¶ó‡¶£‡¶ø‡¶§ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ
‚úî Gradient descent ‡¶ï‡ßÄ‡¶≠‡¶æ‡¶¨‡ßá ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡ßá
‚úî Viva/exam short notes
‚úî Multinomial logistic regression for deep learning (softmax layer)

‡¶¨‡¶≤‡¶≤‡ßá‡¶á ‡¶≤‡¶ø‡¶ñ‡ßá ‡¶¶‡¶ø‡¶ö‡ßç‡¶õ‡¶ø!
