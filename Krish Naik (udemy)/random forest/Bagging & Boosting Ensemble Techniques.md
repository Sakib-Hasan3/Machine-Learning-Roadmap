# Bagging & Boosting Ensemble Techniques

---

## ЁЯФ╖ Ensemble Learning ржХрзА?

**Ensemble Learning** ржорж╛ржирзЗ рж╣рж▓рзЛтАФржПржХрж╛ржзрж┐ржХ **weak model** (ржжрзБрж░рзНржмрж▓ ржоржбрзЗрж▓) ржПржХрж╕рж╛ржерзЗ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржПржХржЯрж┐ **strong model** рждрзИрж░рж┐ ржХрж░рж╛, ржпрзЗржи рж╕рж╛ржоржЧрзНрж░рж┐ржХржнрж╛ржмрзЗ prediction ржЖрж░ржУ ржнрж╛рж▓рзЛ рж╣рзЯред

---

# ЁЯЯв Bagging (Bootstrap Aggregating)

![Image](https://dataaspirant.com/wp-content/uploads/2020/09/8-Difference-Between-Bagging-and-Boosting.png)

![Image](https://miro.medium.com/0%2AfXQq704fHO18BImx.png)

![Image](https://miro.medium.com/1%2Aa6hnuJ8WM37mLimHfMORmQ.png)

### ЁЯУМ Bagging ржХрзА?

**Bagging** рж╣рж▓рзЛ ржПржоржи ржПржХржЯрж┐ ржкржжрзНржзрждрж┐ ржпрзЗржЦрж╛ржирзЗ:

- ржПржХржЗ dataset ржерзЗржХрзЗ **random sampling (with replacement)** ржХрж░рзЗ
- ржПржХрж╛ржзрж┐ржХ model train ржХрж░рж╛ рж╣рзЯ
- рж╢рзЗрж╖рзЗ рждрж╛ржжрзЗрж░ prediction **average (regression)** ржмрж╛ **majority vote (classification)** ржжрж┐рзЯрзЗ combine ржХрж░рж╛ рж╣рзЯ

---

### тЪЩя╕П Bagging ржХрзАржнрж╛ржмрзЗ ржХрж╛ржЬ ржХрж░рзЗ?

1. Original dataset ржерзЗржХрзЗ random sample ржирзЗржУрзЯрж╛ рж╣рзЯ (Bootstrap)
2. ржкрзНрж░рждрж┐ржЯрж┐ sample ржжрж┐рзЯрзЗ ржЖрж▓рж╛ржжрж╛ ржЖрж▓рж╛ржжрж╛ model train ржХрж░рж╛ рж╣рзЯ
3. рж╕ржм model ржПрж░ output ржПржХрждрзНрж░рзЗ combine ржХрж░рж╛ рж╣рзЯ

---

### ЁЯОп Bagging ржХрзЗржи ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ рж╣рзЯ?

- **Variance ржХржорж╛ржирзЛрж░ ржЬржирзНржп**
- Overfitting ржХржорж╛рждрзЗ
- High-variance model (ржпрзЗржоржи Decision Tree) ржХрзЗ stable ржХрж░рждрзЗ

---

### ЁЯза ржЙржжрж╛рж╣рж░ржг

ржзрж░рж╛ ржпрж╛ржХ 1000ржЯрж╛ data ржЖржЫрзЗ

тЖТ Randomржнрж╛ржмрзЗ 1000 data ржирж┐рзЯрзЗ 10ржЯрж╛ dataset ржмрж╛ржирж╛ржирзЛ рж╣рж▓рзЛ

тЖТ ржкрзНрж░рждрж┐ржЯрж╛ dataset ржжрж┐рзЯрзЗ ржЖрж▓рж╛ржжрж╛ Decision Tree train

тЖТ рж╢рзЗрж╖ prediction = рж╕ржм tree ржПрж░ vote

---

### тЬЕ Bagging ржПрж░ рж╕рзБржмрж┐ржзрж╛

- Overfitting ржХржорж╛рзЯ
- Parallel training рж╕ржорзНржнржм
- Noise-ржПрж░ ржкрзНрж░ржнрж╛ржм ржХржорзЗ

### тЭМ ржЕрж╕рзБржмрж┐ржзрж╛

- Bias ржХржорж╛рзЯ ржирж╛
- ржЕржирзЗржХ model рж▓рж╛ржЧрж╛рзЯ тЖТ computation ржмрзЗрж╢рж┐

---

### ЁЯМ│ ржЬржиржкрзНрж░рж┐рзЯ Bagging Algorithm

- **Random Forest** (рж╕ржмржЪрзЗрзЯрзЗ ржЬржиржкрзНрж░рж┐рзЯ)

---

# ЁЯФ╡ Boosting

![Image](https://miro.medium.com/1%2A4XuD6oRrgVqtaSwH-cu6SA.png)

![Image](https://substackcdn.com/image/fetch/f_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A//substack-post-media.s3.amazonaws.com/public/images/3ed1ed6d-2387-47f9-817e-26cfd74843ce_2667x1939.png)

![Image](https://www.researchgate.net/publication/351542039/figure/fig1/AS%3A11431281172877200%401688685833363/Flow-diagram-of-gradient-boosting-machine-learning-method-The-ensemble-classifiers.png)

### ЁЯУМ Boosting ржХрзА?

**Boosting** рж╣рж▓рзЛ ржПржХржЯрж┐ **sequential technique**, ржпрзЗржЦрж╛ржирзЗ:

- Model ржЧрзБрж▓рзЛ ржПржХржЯрж╛рж░ ржкрж░ ржПржХржЯрж╛ train рж╣рзЯ
- ржЖржЧрзЗрж░ model ржпрзЗрж╕ржм data ржнрзБрж▓ ржХрж░рзЗржЫрзЗ, ржкрж░рзЗрж░ model рж╕рзЗржЧрзБрж▓рзЛрж░ ржЙржкрж░ ржмрзЗрж╢рж┐ ржЧрзБрж░рзБрждрзНржм ржжрзЗрзЯ

---

### тЪЩя╕П Boosting ржХрзАржнрж╛ржмрзЗ ржХрж╛ржЬ ржХрж░рзЗ?

1. ржкрзНрж░ржержо model train рж╣рзЯ (simple rule)
2. ржнрзБрж▓ prediction ржкрж╛ржУрзЯрж╛ data-ржХрзЗ ржмрзЗрж╢рж┐ weight ржжрзЗржУрзЯрж╛ рж╣рзЯ
3. ржкрж░рзЗрж░ model рж╕рзЗржЗ ржнрзБрж▓ржЧрзБрж▓рзЛ ржарж┐ржХ ржХрж░рж╛рж░ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзЗ
4. рж╕ржм model ржорж┐рж▓рж┐рзЯрзЗ final prediction рждрзИрж░рж┐ рж╣рзЯ

---

### ЁЯОп Boosting ржХрзЗржи ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ рж╣рзЯ?

- **Bias ржХржорж╛ржирзЛрж░ ржЬржирзНржп**
- Weak learner ржХрзЗ strong learner ржмрж╛ржирж╛рждрзЗ
- Complex pattern ржзрж░рждрзЗ

---

### ЁЯза ржЙржжрж╛рж╣рж░ржг

- Model-1 ржХрж┐ржЫрзБ data ржнрзБрж▓ ржХрж░рж▓рзЛ
- Model-2 ржР ржнрзБрж▓ data-ржЧрзБрж▓рзЛрж░ ржжрж┐ржХрзЗ ржмрзЗрж╢рж┐ ржиржЬрж░ ржжрж┐рж▓
- Model-3 ржЖрж░ржУ fine correction ржХрж░рж▓рзЛ
    
    тЖТ Final model ржЕржирзЗржХ рж╢ржХрзНрждрж┐рж╢рж╛рж▓рзА рж╣рж▓рзЛ
    

---

### тЬЕ Boosting ржПрж░ рж╕рзБржмрж┐ржзрж╛

- Accuracy ржЕржирзЗржХ ржмрзЗрж╢рж┐
- Bias ржУ Variance ржжрзБржЯрзЛржЗ ржХржорж╛рждрзЗ ржкрж╛рж░рзЗ
- Complex data ржнрж╛рж▓рзЛржнрж╛ржмрзЗ handle ржХрж░рзЗ

### тЭМ ржЕрж╕рзБржмрж┐ржзрж╛

- Noise ржерж╛ржХрж▓рзЗ overfitting рж╣рждрзЗ ржкрж╛рж░рзЗ
- Sequential рж╣ржУрзЯрж╛рзЯ training slow
- Parameter tuning sensitive

---

### ЁЯЪА ржЬржиржкрзНрж░рж┐рзЯ Boosting Algorithm

- **AdaBoost**
- **Gradient Boosting**
- **XGBoost**
- **LightGBM**
- **CatBoost**

---

# ЁЯЯа Bagging vs Boosting (рж╕рж╣ржЬ рждрзБрж▓ржирж╛)

| ржмрж┐рж╖рзЯ | Bagging | Boosting |
| --- | --- | --- |
| Training | Parallel | Sequential |
| Focus | Variance ржХржорж╛ржирзЛ | Bias ржХржорж╛ржирзЛ |
| Data Sampling | Random (equal weight) | Wrong data-рждрзЗ ржмрзЗрж╢рж┐ weight |
| Overfitting | ржХржорж╛рзЯ | Noise ржерж╛ржХрж▓рзЗ ржмрж╛рзЬрждрзЗ ржкрж╛рж░рзЗ |
| Example | Random Forest | XGBoost |

---

# ЁЯза рж╕рж╣ржЬржнрж╛ржмрзЗ ржоржирзЗ рж░рж╛ржЦрж╛рж░ ржХрзМрж╢рж▓

- **Bagging = тАЬрж╕ржмрж╛ржЗ рж╕ржорж╛ржитАЭ**
- **Boosting = тАЬржпрзЗ ржнрзБрж▓ ржХрж░рзЗржЫрзЗ, рждрж╛ржХрзЗржЗ ржмрзЗрж╢рж┐ рж╢рзЗржЦрж╛ржУтАЭ**

---

ржЖржкржирж┐ ржЪрж╛ржЗрж▓рзЗ ржЖржорж┐ ржПржЯрж┐ **Notion format**, **Viva ржкрзНрж░рж╢рзНржи-ржЙрждрзНрждрж░**, ржЕржержмрж╛ **Real-life example + math intuition** ржжрж┐рзЯрзЗржУ ржмрзНржпрж╛ржЦрзНржпрж╛ ржХрж░рзЗ ржжрж┐рждрзЗ ржкрж╛рж░рж┐ ЁЯШК