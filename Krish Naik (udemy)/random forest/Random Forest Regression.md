# Random Forest Regression

ЁЯМ│ Random Forest Regression ржХрзА?

---

![Image](https://cdn.prod.website-files.com/5e6f9b297ef3941db2593ba1/5f6315207ab68b113cf57b1c_Screenshot%202020-09-17%20at%2009.49.20.png)

![Image](https://www.researchgate.net/publication/303835073/figure/fig3/AS%3A377949833449472%401467121670301/The-flowchart-of-random-forest-RF-for-regression-adapted-from-Rodriguez-Galiano-et.png)

[Image](https://miro.medium.com/v2/resize%3Afit%3A1400/0%2AYEwFetXQGPB8aDFV)

**Random Forest Regression** рж╣рж▓рзЛ ржПржХржЯрж┐ **Ensemble Learning** ржкржжрзНржзрждрж┐, ржпрзЗржЦрж╛ржирзЗ

ЁЯСЙ ржЕржирзЗржХржЧрзБрж▓рзЛ **Decision Tree (Regression Tree)** ржПржХрж╕рж╛ржерзЗ train ржХрж░рж╛ рж╣рзЯ

ЁЯСЙ ржПржмржВ рж╕ржмржЧрзБрж▓рзЛрж░ prediction-ржПрж░ **average** ржирж┐рзЯрзЗ final output ржжрзЗржУрзЯрж╛ рж╣рзЯред

ЁЯСЙ ржПржЯрж┐ ржорзВрж▓ржд **Bagging (Bootstrap Aggregating)** ржПрж░ ржЙржкрж░ ржнрж┐рждрзНрждрж┐ ржХрж░рзЗ рждрзИрж░рж┐ред

---

## ЁЯза рж╕рж╣ржЬ ржнрж╛рж╖рж╛рзЯ ржзрж╛рж░ржгрж╛

ржПржХржЯрж╛ tree ржнрзБрж▓ ржХрж░рждрзЗ ржкрж╛рж░рзЗ тЭМ

ржХрж┐ржирзНрждрзБ 100ржЯрж╛ tree ржПржХрж╕рж╛ржерзЗ ржЧрзЬ ржХрж░рж▓рзЗ ржнрзБрж▓ ржЕржирзЗржХ ржХржорзЗ ржпрж╛рзЯ тЬЕ

ЁЯУМ **Final Prediction = рж╕ржм tree ржПрж░ prediction-ржПрж░ ржЧрзЬ (mean)**

---

## тЪЩя╕П Random Forest Regression ржХрзАржнрж╛ржмрзЗ ржХрж╛ржЬ ржХрж░рзЗ?

### ржзрж╛ржктАУрзз: Bootstrap Sampling

- Original dataset ржерзЗржХрзЗ **random sampling (with replacement)** ржХрж░рж╛ рж╣рзЯ
- ржкрзНрж░рждрж┐ржЯрж┐ tree ржЖрж▓рж╛ржжрж╛ dataset ржкрж╛рзЯ

### ржзрж╛ржктАУрзи: Multiple Decision Tree Train

- ржкрзНрж░рждрж┐ржЯрж┐ dataset ржжрж┐рзЯрзЗ ржПржХржЯрж┐ ржХрж░рзЗ **Regression Tree** train рж╣рзЯ
- ржкрзНрж░рждрж┐ржЯрж┐ split ржП **random subset of features** ржирзЗржУрзЯрж╛ рж╣рзЯ

### ржзрж╛ржктАУрзй: Prediction

- ржирждрзБржи input ржжрж┐рж▓рзЗ тЖТ
- рж╕ржм tree prediction ржжрзЗрзЯ тЖТ
- **Average = Final Output**

---

## ЁЯУР Mathematical Intuition (рж╕рж╣ржЬ)

ржзрж░рж╛ ржпрж╛ржХ 5ржЯрж╛ tree prediction ржжрж┐рж▓рзЛ:

```
Tree 1 тЖТ 52
Tree 2 тЖТ 55
Tree 3 тЖТ 50
Tree 4 тЖТ 53
Tree 5 тЖТ 54

```

ЁЯСЙ Final Prediction:

[

\frac{52 + 55 + 50 + 53 + 54}{5} = 52.8

]

---

## ЁЯОп Random Forest Regression ржХрзЗржи ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ рж╣рзЯ?

тЬФ Overfitting ржХржорж╛рждрзЗ

тЬФ High variance problem solve ржХрж░рждрзЗ

тЬФ Non-linear relationship ржзрж░рждрзЗ

тЬФ Feature scaling ржЫрж╛рзЬрж╛ржЗ ржХрж╛ржЬ ржХрж░рждрзЗ

---

## ЁЯМЯ Key Hyperparameters (ржЦрзБржм ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг)

| Parameter | ржХрж╛ржЬ |
| --- | --- |
| `n_estimators` | ржХрждржЧрзБрж▓рзЛ tree рж╣ржмрзЗ |
| `max_depth` | tree ржХрждржЯрж╛ ржЧржнрзАрж░ рж╣ржмрзЗ |
| `min_samples_split` | split ржХрж░рж╛рж░ minimum sample |
| `min_samples_leaf` | leaf node ржП minimum sample |
| `max_features` | ржкрзНрж░рждрж┐ржЯрж┐ split ржП ржХржд feature ржирзЗржУрзЯрж╛ рж╣ржмрзЗ |

ЁЯУМ **Tip:**

- `n_estimators тЖС` тЖТ stability тЖС
- `max_depth тЖУ` тЖТ overfitting тЖУ

---

## тЬЕ Random Forest Regression ржПрж░ рж╕рзБржмрж┐ржзрж╛

тЬФ Overfitting ржХржо

тЬФ High accuracy

тЬФ Outlier & noise robust

тЬФ Feature importance ржкрж╛ржУрзЯрж╛ ржпрж╛рзЯ

тЬФ Scaling ржжрж░ржХрж╛рж░ рж╣рзЯ ржирж╛

---

## тЭМ ржЕрж╕рзБржмрж┐ржзрж╛

тЭМ Model heavy (memory ржмрзЗрж╢рж┐ рж▓рж╛ржЧрзЗ)

тЭМ Training slow (tree ржмрзЗрж╢рж┐ рж╣рж▓рзЗ)

тЭМ Explain ржХрж░рж╛ single tree ржерзЗржХрзЗ ржХржарж┐ржи

---

## ЁЯУК Random Forest vs Linear Regression

| ржмрж┐рж╖рзЯ | Linear Regression | Random Forest |
| --- | --- | --- |
| Relationship | Linear | Non-linear |
| Overfitting | Sensitive | Robust |
| Feature scaling | ржжрж░ржХрж╛рж░ | ржжрж░ржХрж╛рж░ ржирзЗржЗ |
| Accuracy | LowтАУMedium | High |
| Interpretability | High | Medium |

---

## ЁЯзк ржХрзЛржерж╛рзЯ ржмрзЗрж╢рж┐ ржмрзНржпржмрж╣рж╛рж░ рж╣рзЯ?

- House price prediction ЁЯПа
- Sales forecasting ЁЯУИ
- Weather prediction ЁЯМж
- Medical cost estimation ЁЯПе
- Stock-related regression (features-based) ЁЯУК

---

## ЁЯза ржоржирзЗ рж░рж╛ржЦрж╛рж░ ржХрзМрж╢рж▓

ЁЯСЙ **Random Forest Regression =ржЕржирзЗржХ Decision Tree + Average = Stable Prediction**

---