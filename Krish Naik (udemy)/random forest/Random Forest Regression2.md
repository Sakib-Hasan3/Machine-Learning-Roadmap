# Random Forest Regression

---

## ðŸŒ³ Random Forest Regression à¦•à§€?

![Image](https://cdn.prod.website-files.com/5e6f9b297ef3941db2593ba1/5f6315207ab68b113cf57b1c_Screenshot%202020-09-17%20at%2009.49.20.png)

![Image](https://www.researchgate.net/publication/303835073/figure/fig3/AS%3A377949833449472%401467121670301/The-flowchart-of-random-forest-RF-for-regression-adapted-from-Rodriguez-Galiano-et.png)

[Image](https://miro.medium.com/v2/resize%3Afit%3A1400/0%2AYEwFetXQGPB8aDFV)

**Random Forest Regression** à¦¹à¦²à§‹ à¦à¦•à¦Ÿà¦¿ **Ensemble Learning** à¦ªà¦¦à§à¦§à¦¤à¦¿, à¦¯à§‡à¦–à¦¾à¦¨à§‡

ðŸ‘‰ à¦…à¦¨à§‡à¦•à¦—à§à¦²à§‹ **Decision Tree (Regression Tree)** à¦à¦•à¦¸à¦¾à¦¥à§‡ train à¦•à¦°à¦¾ à¦¹à§Ÿ

ðŸ‘‰ à¦à¦¬à¦‚ à¦¸à¦¬à¦—à§à¦²à§‹ tree-à¦à¦° prediction à¦à¦° **à¦—à§œ (average)** à¦¨à¦¿à§Ÿà§‡ final output à¦¦à§‡à¦“à§Ÿà¦¾ à¦¹à§Ÿà¥¤

ðŸ“Œ à¦à¦Ÿà¦¿ à¦®à§‚à¦²à¦¤ **Bagging (Bootstrap Aggregating)** à¦•à§Œà¦¶à¦²à§‡à¦° à¦‰à¦ªà¦° à¦­à¦¿à¦¤à§à¦¤à¦¿ à¦•à¦°à§‡ à¦¤à§ˆà¦°à¦¿à¥¤

---

## ðŸ§  à¦¸à¦¹à¦œà¦­à¦¾à¦¬à§‡ à¦¬à§à¦à¦²à§‡

à¦à¦•à¦Ÿà¦¾ Decision Tree à¦­à§à¦² à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à§‡ âŒ

à¦•à¦¿à¦¨à§à¦¤à§ 100à¦Ÿà¦¾ Decision Tree-à¦à¦° à¦—à§œ à¦¨à¦¿à¦²à§‡ à¦­à§à¦² à¦…à¦¨à§‡à¦• à¦•à¦®à§‡ à¦¯à¦¾à§Ÿ âœ…

ðŸ‘‰ **Final Prediction = à¦¸à¦¬ tree à¦à¦° prediction-à¦à¦° à¦—à§œ**

---

## âš™ï¸ Random Forest Regression à¦•à§€à¦­à¦¾à¦¬à§‡ à¦•à¦¾à¦œ à¦•à¦°à§‡?

### ðŸ”¹ à¦§à¦¾à¦ªâ€“à§§: Bootstrap Sampling

- Original dataset à¦¥à§‡à¦•à§‡ **random sampling (with replacement)** à¦•à¦°à¦¾ à¦¹à§Ÿ
- à¦ªà§à¦°à¦¤à¦¿à¦Ÿà¦¿ tree à¦†à¦²à¦¾à¦¦à¦¾ à¦†à¦²à¦¾à¦¦à¦¾ dataset à¦ªà¦¾à§Ÿ

---

### ðŸ”¹ à¦§à¦¾à¦ªâ€“à§¨: Multiple Regression Tree Train

- à¦ªà§à¦°à¦¤à¦¿à¦Ÿà¦¿ dataset à¦¦à¦¿à§Ÿà§‡ à¦à¦•à¦Ÿà¦¿ à¦•à¦°à§‡ **Regression Tree** train à¦¹à§Ÿ
- à¦ªà§à¦°à¦¤à¦¿à¦Ÿà¦¿ split-à¦ à¦¸à¦¬ feature à¦¨à¦¾ à¦¨à¦¿à§Ÿà§‡ **random subset of features** à¦¨à§‡à¦“à§Ÿà¦¾ à¦¹à§Ÿ

---

### ðŸ”¹ à¦§à¦¾à¦ªâ€“à§©: Prediction

- à¦¨à¦¤à§à¦¨ input à¦¦à¦¿à¦²à§‡ â†’
- à¦¸à¦¬ tree prediction à¦¦à§‡à§Ÿ â†’
- à¦¸à¦¬ prediction à¦à¦° **average** = final output

---

## ðŸ“ Mathematical Intuition (à¦¸à¦¹à¦œ)

à¦§à¦°à¦¾ à¦¯à¦¾à¦• 5à¦Ÿà¦¾ tree à¦¨à¦¿à¦šà§‡à¦° prediction à¦¦à¦¿à¦²à§‹:

```
Tree 1 â†’ 52000
Tree 2 â†’ 54000
Tree 3 â†’ 51000
Tree 4 â†’ 53000
Tree 5 â†’ 55000

```

ðŸ‘‰ Final Prediction:

[

\frac{52000 + 54000 + 51000 + 53000 + 55000}{5} = 53000

]

---

## ðŸŽ¯ Random Forest Regression à¦•à§‡à¦¨ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à¦¾ à¦¹à§Ÿ?

âœ” Overfitting à¦•à¦®à¦¾à¦¤à§‡

âœ” High variance à¦¸à¦®à¦¸à§à¦¯à¦¾ à¦¸à¦®à¦¾à¦§à¦¾à¦¨ à¦•à¦°à¦¤à§‡

âœ” Non-linear relationship à¦§à¦°à¦¤à§‡

âœ” Outlier à¦“ noise handle à¦•à¦°à¦¤à§‡

âœ” Feature scaling à¦›à¦¾à§œà¦¾à¦‡ à¦­à¦¾à¦²à§‹ à¦•à¦¾à¦œ à¦•à¦°à¦¤à§‡

---

## ðŸŒŸ à¦—à§à¦°à§à¦¤à§à¦¬à¦ªà§‚à¦°à§à¦£ Hyperparameters

| Hyperparameter | à¦•à¦¾à¦œ |
| --- | --- |
| `n_estimators` | à¦•à§Ÿà¦Ÿà¦¾ tree à¦¹à¦¬à§‡ |
| `max_depth` | tree à¦•à¦¤ à¦—à¦­à§€à¦° à¦¹à¦¬à§‡ |
| `min_samples_split` | split à¦•à¦°à¦¾à¦° à¦œà¦¨à§à¦¯ minimum sample |
| `min_samples_leaf` | leaf node-à¦ minimum sample |
| `max_features` | à¦ªà§à¦°à¦¤à¦¿ split-à¦ à¦•à§Ÿà¦Ÿà¦¾ feature à¦¨à§‡à¦“à§Ÿà¦¾ à¦¹à¦¬à§‡ |

ðŸ“Œ **Tip:**

- `n_estimators â†‘` â†’ stability â†‘
- `max_depth â†“` â†’ overfitting â†“

---

## âœ… Random Forest Regression à¦à¦° à¦¸à§à¦¬à¦¿à¦§à¦¾

âœ” High accuracy

âœ” Overfitting à¦•à¦®

âœ” Noise à¦“ outlier robust

âœ” Feature importance à¦ªà¦¾à¦“à§Ÿà¦¾ à¦¯à¦¾à§Ÿ

âœ” Complex data à¦­à¦¾à¦²à§‹à¦­à¦¾à¦¬à§‡ handle à¦•à¦°à§‡

---

## âŒ à¦…à¦¸à§à¦¬à¦¿à¦§à¦¾

âŒ Model heavy (memory à¦¬à§‡à¦¶à¦¿ à¦²à¦¾à¦—à§‡)

âŒ Training time à¦¬à§‡à¦¶à¦¿

âŒ Single tree à¦à¦° à¦®à¦¤à§‹ explain à¦•à¦°à¦¾ à¦•à¦ à¦¿à¦¨

---

## ðŸ“Š Linear Regression vs Random Forest Regression

| à¦¬à¦¿à¦·à§Ÿ | Linear Regression | Random Forest Regression |
| --- | --- | --- |
| Relationship | Linear | Non-linear |
| Overfitting | à¦¬à§‡à¦¶à¦¿ à¦¹à§Ÿ | à¦•à¦® à¦¹à§Ÿ |
| Feature scaling | à¦¦à¦°à¦•à¦¾à¦° | à¦¦à¦°à¦•à¦¾à¦° à¦¨à§‡à¦‡ |
| Accuracy | à¦¤à§à¦²à¦¨à¦¾à¦®à§‚à¦²à¦• à¦•à¦® | à¦¬à§‡à¦¶à¦¿ |

---

## ðŸ§ª à¦•à§‹à¦¥à¦¾à§Ÿ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦¹à§Ÿ?

- House price prediction ðŸ 
- Salary prediction ðŸ’°
- Sales forecasting ðŸ“ˆ
- Medical cost estimation ðŸ¥
- Travel / tourism cost prediction âœˆï¸

---

## ðŸŽ¤ Viva / Interview Q&A (Bangla)

**Q: Random Forest Regression à¦•à§€?**

ðŸ‘‰ Multiple regression tree à¦à¦° average à¦¦à¦¿à§Ÿà§‡ prediction à¦•à¦°à¦¾

**Q: à¦à¦Ÿà¦¾ Bagging à¦¨à¦¾ Boosting?**

ðŸ‘‰ **Bagging**

**Q: Overfitting à¦•à§‡à¦¨ à¦•à¦® à¦¹à§Ÿ?**

ðŸ‘‰ Random sampling + feature randomness à¦à¦° à¦œà¦¨à§à¦¯

**Q: Feature scaling à¦¦à¦°à¦•à¦¾à¦°?**

ðŸ‘‰ à¦¨à¦¾

---

## ðŸ§  à¦à¦• à¦²à¦¾à¦‡à¦¨à§‡ à¦®à¦¨à§‡ à¦°à¦¾à¦–à§à¦¨

> Random Forest Regression = à¦…à¦¨à§‡à¦• Decision Tree + Average = Stable Prediction
> 

---