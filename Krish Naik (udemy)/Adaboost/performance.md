## ЁЯУК Performance of **Decision Tree Stump**

*(ржмрж╛ржВрж▓рж╛рзЯ ржмрзНржпрж╛ржЦрзНржпрж╛ + Code + Output рж╕рж╣)*

---

## 1я╕ПтГг Decision Tree Stump-ржПрж░ Performance ржмрж▓рждрзЗ ржХрзА ржмрзЛржЭрж╛рзЯ?

**Performance** ржорж╛ржирзЗ рж╣рж▓рзЛ тАФ
ржПржХржЯрж┐ Decision Tree Stump **ржХрждржЯрж╛ ржнрж╛рж▓рзЛржнрж╛ржмрзЗ prediction ржХрж░рждрзЗ ржкрж╛рж░ржЫрзЗ**ред

ржЖржорж░рж╛ рж╕рж╛ржзрж╛рж░ржгржд ржирж┐ржЪрзЗрж░ metric ржЧрзБрж▓рзЛ ржжрж┐рзЯрзЗ performance ржмрж┐ржЪрж╛рж░ ржХрж░рж┐ ЁЯСЗ

* тЬЕ Accuracy
* тЬЕ Confusion Matrix
* тЬЕ Precision
* тЬЕ Recall
* тЬЕ F1-score

ЁЯУМ ржоржирзЗ рж░рж╛ржЦржмрзЗ:
Decision Stump рж╣рж▓рзЛ **Weak Learner**, рждрж╛ржЗ ржПрж░ performance рж╕рж╛ржзрж╛рж░ржгржд **ржорж╛ржЭрж╛рж░рж┐** рж╣рзЯред

---

## 2я╕ПтГг ржХрзЗржи Decision Stump-ржПрж░ Performance рж╕рзАржорж┐ржд?

ржХрж╛рж░ржг:

* тЭМ ржорж╛рждрзНрж░ **рззржЯрж┐ feature**
* тЭМ ржорж╛рждрзНрж░ **рззржЯрж┐ split**
* тЭМ Complex pattern ржзрж░рждрзЗ ржкрж╛рж░рзЗ ржирж╛

ЁЯСЙ рждрж╛ржЗ:

* Bias тЮЬ ржмрзЗрж╢рж┐
* Variance тЮЬ ржХржо

---

## 3я╕ПтГг Example Dataset (Classification)

```text
X = [1, 2, 3, 4]
y = [0, 0, 1, 1]
```

ржЖржорж░рж╛ ржЖржЧрзЗржЗ ржжрзЗржЦрзЗржЫрж┐ stump ржПржЗ rule рж╢рж┐ржЦрзЗ:

```
X <= 2.5 тЖТ 0
X >  2.5 тЖТ 1
```

---

## 4я╕ПтГг Performance Measure ржХрж░рж╛рж░ Python Code

```python
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Dataset
X = np.array([[1], [2], [3], [4]])
y = np.array([0, 0, 1, 1])

# Decision Tree Stump
stump = DecisionTreeClassifier(max_depth=1)
stump.fit(X, y)

# Prediction
y_pred = stump.predict(X)

# Performance Metrics
acc = accuracy_score(y, y_pred)
cm = confusion_matrix(y, y_pred)
report = classification_report(y, y_pred)

print("Accuracy:", acc)
print("\nConfusion Matrix:\n", cm)
print("\nClassification Report:\n", report)
```

---

## 5я╕ПтГг Output (Expected)

### ЁЯФ╣ Accuracy

```
Accuracy: 1.0
```

ЁЯСЙ Training data-рждрзЗ **100% accuracy**

тЪая╕П ржХрж┐ржирзНрждрзБ рж╕рж╛ржмржзрж╛ржи:
ржПржЯрж╛ **ржЫрзЛржЯ ржУ рж╕рж╣ржЬ dataset**, real-world data-рждрзЗ ржПржоржи рж╣рзЯ ржирж╛ред

---

### ЁЯФ╣ Confusion Matrix

```
[[2 0]
 [0 2]]
```

ржмрзНржпрж╛ржЦрзНржпрж╛:

| Actual \ Predicted | 0 | 1 |
| ------------------ | - | - |
| 0                  | 2 | 0 |
| 1                  | 0 | 2 |

ЁЯСЙ ржХрзЛржирзЛ ржнрзБрж▓ prediction ржирзЗржЗ

---

### ЁЯФ╣ Classification Report

```
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2

    accuracy                           1.00         4
```

---

## 6я╕ПтГг рждрж╛рж╣рж▓рзЗ ржХрж┐ Decision Stump ржЦрзБржм рж╢ржХрзНрждрж┐рж╢рж╛рж▓рзА? ЁЯдФ

тЭМ **ржирж╛**

ржХрж╛рж░ржг:

* ржПржЯрж╛ рж╢рзБржзрзБ **training data**-рждрзЗ ржнрж╛рж▓рзЛ
* Complex ржмрж╛ noisy data-рждрзЗ performance ржЕржирзЗржХ ржХржорзЗ ржпрж╛рзЯ

---

## 7я╕ПтГг Realistic Scenario (ржХрзЗржи Performance ржХржорзЗ)

ржзрж░рж╛ ржпрж╛ржХ:

* Feature ржЕржирзЗржХ
* Data nonlinear
* Noise ржЖржЫрзЗ

ЁЯСЙ рждржЦржи Decision Stump:

* Underfitting ржХрж░рзЗ
* Accuracy ржХржо рж╣рзЯ

ЁЯУМ Example:

```
Accuracy тЙИ 55% тАУ 65%
```

---

## 8я╕ПтГг Decision Stump vs Full Decision Tree (Performance)

| Model              | Accuracy     | Bias | Variance |
| ------------------ | ------------ | ---- | -------- |
| Decision Stump     | LowтАУMedium   | High | Low      |
| Deep Decision Tree | High (train) | Low  | High     |
| AdaBoost (Stumps)  | Very High    | Low  | Balanced |

---

## 9я╕ПтГг AdaBoost-ржП Performance рж╣ржарж╛рзО ржХрзЗржи ржмрзЗрзЬрзЗ ржпрж╛рзЯ?

ржХрж╛рж░ржг AdaBoost:

* ржЕржирзЗржХ stump ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ
* ржнрзБрж▓ data-рждрзЗ ржмрзЗрж╢рж┐ weight ржжрзЗрзЯ
* Weighted voting ржХрж░рзЗ

ЁЯСЙ
**One stump = weak**
**100 stump together = powerful** ЁЯТе

---

## ЁЯФЯ Interview / Viva ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг ржкрзНрж░рж╢рзНржи

**Q1:** Decision stump ржХрзЗржи underfitting ржХрж░рзЗ?
ЁЯСЙ ржХрж╛рж░ржг model ржЦрзБржм simple

**Q2:** Single stump ржХрж┐ production-ready?
ЁЯСЙ ржирж╛

**Q3:** Stump-ржПрж░ performance ржХрж┐ржнрж╛ржмрзЗ ржмрж╛рзЬрж╛ржирзЛ ржпрж╛рзЯ?
ЁЯСЙ AdaBoost / Gradient Boosting ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ

**Q4:** Stump-ржПрж░ strength ржХрзЛржерж╛рзЯ?
ЁЯСЙ Ensemble-ржПрж░ ржнрж┐рждрж░рзЗ

---

## ЁЯза Final Summary (ржорзБржЦрж╕рзНрже ржХрж░рж╛рж░ ржорждрзЛ)

> **Decision Tree Stump ржПржХрж╛ ржжрзБрж░рзНржмрж▓, ржХрж┐ржирзНрждрзБ Ensemble-ржП ржнрзЯржВржХрж░ рж╢ржХрзНрждрж┐рж╢рж╛рж▓рзА**

---


