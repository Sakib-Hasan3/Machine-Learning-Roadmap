## üîÅ **Updating Weights in AdaBoost**

*(‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡ßü Step-by-Step ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ + Code + Output ‡¶∏‡¶π)*

![Image](https://substackcdn.com/image/fetch/%24s_%21RxGQ%21%2Cf_auto%2Cq_auto%3Agood%2Cfl_progressive%3Asteep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe32def8b-6361-40fb-8e41-180ba002ef1e_2501x1467.png)

![Image](https://editor.analyticsvidhya.com/uploads/98218100.JPG)

![Image](https://www.researchgate.net/publication/339248555/figure/fig3/AS%3A858292884627456%401581644378703/A-description-of-how-the-AdaBoost-algorithm-works-The-learner-is-incrementally-boosted.ppm)

---

## 1Ô∏è‚É£ Updating Weights ‡¶Æ‡¶æ‡¶®‡ßá ‡¶ï‡ßÄ?

**Updating Weights** ‡¶π‡¶≤‡ßã AdaBoost-‡¶è‡¶∞ ‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶ß‡¶æ‡¶™‡•§

üëâ ‡¶∏‡¶π‡¶ú‡¶≠‡¶æ‡¶¨‡ßá:

* ‚ùå ‡¶Ø‡ßá‡¶∏‡¶¨ data **‡¶≠‡ßÅ‡¶≤‡¶≠‡¶æ‡¶¨‡ßá predict ‡¶π‡ßü‡ßá‡¶õ‡ßá** ‚Üí ‡¶§‡¶æ‡¶¶‡ßá‡¶∞ **weight ‡¶¨‡¶æ‡ßú‡¶æ‡¶®‡ßã ‡¶π‡ßü**
* ‚úÖ ‡¶Ø‡ßá‡¶∏‡¶¨ data **‡¶†‡¶ø‡¶ï‡¶≠‡¶æ‡¶¨‡ßá predict ‡¶π‡ßü‡ßá‡¶õ‡ßá** ‚Üí ‡¶§‡¶æ‡¶¶‡ßá‡¶∞ **weight ‡¶ï‡¶Æ‡¶æ‡¶®‡ßã ‡¶π‡ßü**

üìå ‡¶â‡¶¶‡ßç‡¶¶‡ßá‡¶∂‡ßç‡¶Ø:

> ‚Äú‡¶™‡¶∞‡ßá‡¶∞ weak learner ‡¶Ø‡ßá‡¶® ‡¶Ü‡¶ó‡ßá‡¶∞ ‡¶≠‡ßÅ‡¶≤‡¶ó‡ßÅ‡¶≤‡ßã‡¶∞ ‡¶¶‡¶ø‡¶ï‡ßá ‡¶¨‡ßá‡¶∂‡¶ø ‡¶Æ‡¶®‡ßã‡¶Ø‡ßã‡¶ó ‡¶¶‡ßá‡ßü‚Äù

---

## 2Ô∏è‚É£ ‡¶ï‡ßá‡¶® Weight Update ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞?

‡¶Ø‡¶¶‡¶ø weight update ‡¶®‡¶æ ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü:

* ‡¶∏‡¶¨ weak learner ‡¶è‡¶ï‡¶á ‡¶≠‡ßÅ‡¶≤ ‡¶¨‡¶æ‡¶∞‡¶¨‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá
* Boosting ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡¶¨‡ßá ‡¶®‡¶æ

üëâ Weight update-‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø‡¶á AdaBoost ‚ÄúAdaptive‚Äù

---

## 3Ô∏è‚É£ Weight Update-‡¶è‡¶∞ ‡¶Ü‡¶ó‡ßá ‡¶ï‡ßÄ ‡¶ú‡¶æ‡¶®‡¶æ ‡¶≤‡¶æ‡¶ó‡ßá?

Weight update ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞ üëá

1. **Prediction (≈∑)**
2. **Actual label (y)**
3. **Weighted error**
4. **Alpha (model importance)**

---

## 4Ô∏è‚É£ Step-by-Step Weight Updating (Concept)

### üîπ Step 1: Initial Weights

‡¶ß‡¶∞‡¶æ ‡¶Ø‡¶æ‡¶ï 4‡¶ü‡¶ø data point ‡¶Ü‡¶õ‡ßá:

```
w = [0.25, 0.25, 0.25, 0.25]
```

---

### üîπ Step 2: Weak Learner Prediction

| Index | y (Actual) | ≈∑ (Predicted) |
| ----- | ---------- | ------------- |
| 1     | 0          | 0 ‚úÖ           |
| 2     | 0          | 1 ‚ùå           |
| 3     | 1          | 1 ‚úÖ           |
| 4     | 1          | 1 ‚úÖ           |

---

### üîπ Step 3: Weighted Error Calculation

```
Error = sum(weights of wrong predictions)
Error = 0.25
```

---

### üîπ Step 4: Alpha Calculation

```
alpha = ¬Ω √ó ln((1 ‚àí error) / error)
alpha = ¬Ω √ó ln(0.75 / 0.25)
alpha ‚âà 0.55
```

---

### üîπ Step 5: Weight Update Formula

```
w_new = w_old √ó exp(¬± alpha)
```

* ‚ùå Wrong prediction ‚Üí `+ alpha`
* ‚úÖ Correct prediction ‚Üí `- alpha`

---

### üîπ Step 6: Update Weights (Before Normalization)

| Index | Correct? | New Weight            |
| ----- | -------- | --------------------- |
| 1     | ‚úÖ        | 0.25 √ó e‚Åª‚Å∞¬∑‚Åµ‚Åµ ‚âà 0.144 |
| 2     | ‚ùå        | 0.25 √ó e‚Å∞¬∑‚Åµ‚Åµ ‚âà 0.433  |
| 3     | ‚úÖ        | 0.144                 |
| 4     | ‚úÖ        | 0.144                 |

---

### üîπ Step 7: Normalize Weights

Sum = 0.865

```
Final Weights ‚âà [0.166, 0.500, 0.166, 0.166]
```

üìå ‡¶≠‡ßÅ‡¶≤ data ‡¶è‡¶ñ‡¶® ‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶¨‡ßá‡¶∂‡¶ø ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ (50%)

---

## 5Ô∏è‚É£ Python Code: Weight Updating (Manual)

```python
import numpy as np

# Initial weights
weights = np.array([0.25, 0.25, 0.25, 0.25])

# Actual & predicted labels
y_true = np.array([0, 0, 1, 1])
y_pred = np.array([0, 1, 1, 1])

# Weighted error
error = np.sum(weights[y_true != y_pred])

# Alpha calculation
alpha = 0.5 * np.log((1 - error) / error)

# Update weights
new_weights = []
for i in range(len(weights)):
    if y_true[i] == y_pred[i]:
        new_weights.append(weights[i] * np.exp(-alpha))
    else:
        new_weights.append(weights[i] * np.exp(alpha))

# Normalize
new_weights = np.array(new_weights)
new_weights = new_weights / np.sum(new_weights)

print("Weighted Error:", error)
print("Alpha:", round(alpha, 3))
print("Updated Weights:", np.round(new_weights, 3))
```

---

## 6Ô∏è‚É£ Output (Expected)

```
Weighted Error: 0.25
Alpha: 0.549
Updated Weights: [0.166 0.5   0.166 0.166]
```

---

## 7Ô∏è‚É£ Output ‡¶•‡ßá‡¶ï‡ßá ‡¶ï‡ßÄ ‡¶¨‡ßã‡¶ù‡¶æ ‡¶Ø‡¶æ‡ßü?

* ‚ùå 2nd data point ‡¶≠‡ßÅ‡¶≤ ‡¶π‡ßü‡ßá‡¶õ‡ßá ‚Üí weight = **0.5**
* ‚úÖ ‡¶¨‡¶æ‡¶ï‡¶ø‡¶ó‡ßÅ‡¶≤‡ßã ‡¶†‡¶ø‡¶ï ‚Üí weight ‡¶ï‡¶Æ‡ßá **0.166**
* üëâ ‡¶™‡¶∞‡ßá‡¶∞ stump ‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶¨‡ßá‡¶∂‡¶ø ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡¶¨‡ßá **2nd data ‡¶†‡¶ø‡¶ï ‡¶ï‡¶∞‡¶§‡ßá**

---

## 8Ô∏è‚É£ AdaBoost Loop-‡¶è Weight Updating ‡¶ï‡ßã‡¶•‡¶æ‡ßü?

```
Initialize weights
‚Üì
Train stump
‚Üì
Calculate error
‚Üì
Calculate alpha
‚Üì
Update weights  ‚Üê (THIS STEP)
‚Üì
Normalize
‚Üì
Next iteration
```

---

## 9Ô∏è‚É£ Common Interview / Viva ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®

**Q1:** Weight update ‡¶ï‡ßá‡¶® exponential?
üëâ ‡¶≠‡ßÅ‡¶≤ prediction-‡¶ï‡ßá ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§ highlight ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø

**Q2:** Normalization ‡¶ï‡ßá‡¶® ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞?
üëâ Weight distribution ‡¶†‡¶ø‡¶ï ‡¶∞‡¶æ‡¶ñ‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø

**Q3:** ‡¶Ø‡¶¶‡¶ø error = 0.5 ‡¶π‡ßü?
üëâ Alpha = 0 ‚Üí model useless

**Q4:** Error > 0.5 ‡¶π‡¶≤‡ßá?
üëâ Weak learner reject ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü

---

## üß† ‡¶è‡¶ï ‡¶≤‡¶æ‡¶á‡¶®‡ßá ‡¶Æ‡¶®‡ßá ‡¶∞‡¶æ‡¶ñ‡ßã

> **AdaBoost learns by increasing pain on mistakes** üòÑ
> (‡¶≠‡ßÅ‡¶≤ ‡¶Ø‡¶§ ‡¶¨‡ßá‡¶∂‡¶ø, weight ‡¶§‡¶§ ‡¶¨‡ßá‡¶∂‡¶ø)

---

