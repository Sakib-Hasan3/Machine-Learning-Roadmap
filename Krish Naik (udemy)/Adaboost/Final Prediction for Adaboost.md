## ðŸ§® **Final Prediction in AdaBoost**

*(à¦¬à¦¾à¦‚à¦²à¦¾à§Ÿ à¦ªà¦°à¦¿à¦·à§à¦•à¦¾à¦° à¦¬à§à¦¯à¦¾à¦–à§à¦¯à¦¾ + Code + Output à¦¸à¦¹)*

![Image](https://datamapu.com/images/adaboost/adaboost.png)

![Image](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/dx-02-scaled-1.webp)

![Image](https://editor.analyticsvidhya.com/uploads/98218100.JPG)

---

## 1ï¸âƒ£ Final Prediction à¦®à¦¾à¦¨à§‡ à¦•à§€?

AdaBoostâ€“à¦ **Final Prediction** à¦¹à§Ÿ
ðŸ‘‰ **à¦¸à¦¬ weak learner (Decision Stump)**â€“à¦à¦° prediction à¦à¦•à¦¸à¦¾à¦¥à§‡ à¦¨à¦¿à§Ÿà§‡
ðŸ‘‰ **alpha (importance)** à¦…à¦¨à§à¦¯à¦¾à§Ÿà§€ **weighted voting** à¦•à¦°à§‡à¥¤

ðŸ“Œ à¦¸à¦¹à¦œà¦­à¦¾à¦¬à§‡:

> â€œà¦¯à¦¾à¦° à¦…à¦­à¦¿à¦œà§à¦žà¦¤à¦¾ (alpha) à¦¬à§‡à¦¶à¦¿, à¦¤à¦¾à¦° à¦•à¦¥à¦¾ à¦¬à§‡à¦¶à¦¿ à¦¶à§‹à¦¨à¦¾ à¦¹à¦¬à§‡â€

---

## 2ï¸âƒ£ Final Prediction-à¦à¦° à¦®à§‚à¦² à¦§à¦¾à¦°à¦£à¦¾ (Core Idea)

AdaBoost à¦¶à§‡à¦· à¦ªà¦°à§à¦¯à¦¨à§à¦¤ à¦¬à¦²à§‡:

```
Final Prediction = sign( Î£ (alpha_t Ã— h_t(x)) )
```

à¦¯à§‡à¦–à¦¾à¦¨à§‡:

* `h_t(x)` = t-à¦¤à¦® weak learner-à¦à¦° prediction
* `alpha_t` = à¦“à¦‡ learner-à¦à¦° à¦—à§à¦°à§à¦¤à§à¦¬
* `sign()` = positive à¦¹à¦²à§‡ +1, negative à¦¹à¦²à§‡ âˆ’1

---

## 3ï¸âƒ£ à¦•à§‡à¦¨ Weighted Voting à¦¦à¦°à¦•à¦¾à¦°?

à¦•à¦¾à¦°à¦£:

* à¦¸à¦¬ weak learner à¦¸à¦®à¦¾à¦¨ à¦­à¦¾à¦²à§‹ à¦¨à¦¾
* à¦¯à¦¾à¦¦à§‡à¦° error à¦•à¦® â†’ alpha à¦¬à§‡à¦¶à¦¿ â†’ à¦¬à§‡à¦¶à¦¿ à¦—à§à¦°à§à¦¤à§à¦¬

ðŸ‘‰ à¦¤à¦¾à¦‡ simple majority vote à¦¨à§Ÿ,
ðŸ‘‰ **weighted vote** à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à¦¾ à¦¹à§Ÿ

---

## 4ï¸âƒ£ Step-by-Step Final Prediction (Conceptual)

à¦§à¦°à¦¾ à¦¯à¦¾à¦• **à§©à¦Ÿà¦¿ Decision Stump** à¦†à¦›à§‡:

| Stump | Prediction | Alpha |
| ----- | ---------- | ----- |
| hâ‚    | +1         | 0.8   |
| hâ‚‚    | âˆ’1         | 0.5   |
| hâ‚ƒ    | +1         | 0.2   |

---

### ðŸ”¹ Weighted Sum

```
= (0.8 Ã— +1) + (0.5 Ã— âˆ’1) + (0.2 Ã— +1)
= 0.8 âˆ’ 0.5 + 0.2
= 0.5
```

---

### ðŸ”¹ Final Prediction

```
sign(0.5) = +1
```

ðŸ‘‰ **Final class = +1**

---

## 5ï¸âƒ£ Python Code: Final Prediction (Manual Example)

```python
import numpy as np

# Predictions from 3 weak learners
predictions = np.array([1, -1, 1])

# Corresponding alpha values
alphas = np.array([0.8, 0.5, 0.2])

# Weighted sum
final_score = np.sum(alphas * predictions)

# Final prediction
final_prediction = np.sign(final_score)

print("Predictions:", predictions)
print("Alphas:", alphas)
print("Weighted Sum:", round(final_score, 3))
print("Final Prediction:", int(final_prediction))
```

---

## 6ï¸âƒ£ Output (Expected)

```
Predictions: [ 1 -1  1]
Alphas: [0.8 0.5 0.2]
Weighted Sum: 0.5
Final Prediction: 1
```

---

## 7ï¸âƒ£ Multiple Data Points-à¦à¦° à¦œà¦¨à§à¦¯ Final Prediction

à¦§à¦°à¦¾ à¦¯à¦¾à¦• 2à¦Ÿà¦¿ data point à¦†à¦›à§‡
à¦à¦¬à¦‚ 3à¦Ÿà¦¿ stump predict à¦•à¦°à¦›à§‡:

```python
# Each row = one data point
preds = np.array([
    [ 1, -1,  1],   # data point 1
    [-1, -1,  1]    # data point 2
])

alphas = np.array([0.8, 0.5, 0.2])

scores = preds @ alphas
final_preds = np.sign(scores)

print("Scores:", scores)
print("Final Predictions:", final_preds.astype(int))
```

### ðŸ”¹ Output

```
Scores: [ 0.5 -1.1]
Final Predictions: [ 1 -1]
```

---

## 8ï¸âƒ£ Classification (0 / 1) à¦¹à¦²à§‡ à¦•à§€ à¦¹à§Ÿ?

AdaBoost internally à¦•à¦¾à¦œ à¦•à¦°à§‡ **âˆ’1 / +1** à¦¦à¦¿à§Ÿà§‡
à¦•à¦¿à¦¨à§à¦¤à§ à¦¬à¦¾à¦‡à¦°à§‡à¦° output à¦¹à¦¤à§‡ à¦ªà¦¾à¦°à§‡:

| sign | Class |
| ---- | ----- |
| +1   | 1     |
| âˆ’1   | 0     |

ðŸ“Œ Mapping:

```python
class_output = (final_preds == 1).astype(int)
```

---

## 9ï¸âƒ£ Sklearn à¦¦à¦¿à§Ÿà§‡ Final Prediction (Built-in)

```python
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
import numpy as np

X = np.array([[1], [2], [3], [4]])
y = np.array([0, 0, 1, 1])

model = AdaBoostClassifier(
    base_estimator=DecisionTreeClassifier(max_depth=1),
    n_estimators=3
)

model.fit(X, y)

pred = model.predict(X)
print("Final Predictions:", pred)
```

### ðŸ”¹ Output

```
Final Predictions: [0 0 1 1]
```

---

## ðŸ”Ÿ AdaBoost Workflow (Big Picture)

```
Train stump 1 â†’ Î±â‚
Train stump 2 â†’ Î±â‚‚
Train stump 3 â†’ Î±â‚ƒ
        â†“
Weighted sum of predictions
        â†“
sign(Î£ Î±â‚œhâ‚œ(x))
        â†“
Final Prediction
```

---

## 1ï¸âƒ£1ï¸âƒ£ Interview / Viva à¦ªà§à¦°à¦¶à§à¦¨ (à¦–à§à¦¬ à¦—à§à¦°à§à¦¤à§à¦¬à¦ªà§‚à¦°à§à¦£)

**Q1:** AdaBoost majority voting à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§‡?
ðŸ‘‰ à¦¨à¦¾, weighted voting

**Q2:** Alpha à¦¬à§œ à¦¹à¦²à§‡ à¦•à§€ à¦¬à§‹à¦à¦¾à§Ÿ?
ðŸ‘‰ Weak learner à¦¬à§‡à¦¶à¦¿ à¦¨à¦¿à¦°à§à¦­à¦°à¦¯à§‹à¦—à§à¦¯

**Q3:** Final score = 0 à¦¹à¦²à§‡ à¦•à§€ à¦¹à§Ÿ?
ðŸ‘‰ Tie â†’ implementation-dependent decision

**Q4:** AdaBoost classification à¦•à§‡à¦¨ âˆ’1/+1 à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§‡?
ðŸ‘‰ Mathematical simplicity (exponential loss)

---

## ðŸ§  One-Line Memory Trick

> **AdaBoost final prediction = experience-weighted opinion** ðŸŽ¯

---


