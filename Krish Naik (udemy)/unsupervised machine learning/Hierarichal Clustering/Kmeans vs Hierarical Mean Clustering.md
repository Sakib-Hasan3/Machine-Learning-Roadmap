![Image](https://miro.medium.com/1%2ATs9tsjeygQPgCRhzeXC5zQ.png)

![Image](https://miro.medium.com/1%2Arw8IUza1dbffBhiA4i0GNQ.png)

![Image](https://towardsdatascience.com/wp-content/uploads/2021/05/1VvOVxdBb74IOxxF2RmthCQ.png)

![Image](https://scikit-learn.org/stable/_images/sphx_glr_plot_agglomerative_dendrogram_001.png)

## ðŸ”· **K-Means vs Hierarchical (Agglomerative) Clustering** â€” à¦¸à¦¹à¦œ à¦“ à¦ªà¦°à¦¿à¦·à§à¦•à¦¾à¦° à¦¤à§à¦²à¦¨à¦¾

à¦¨à¦¿à¦šà§‡ à¦¦à§à¦‡à¦Ÿà¦¾ algorithm **à¦•à¦¿ à¦•à¦°à§‡, à¦•à¦¿à¦­à¦¾à¦¬à§‡ à¦•à¦°à§‡, à¦•à¦–à¦¨ à¦•à§‹à¦¨à¦Ÿà¦¾ à¦¨à§‡à¦¬à§‡à¦¨**â€”à¦¸à¦¬ à¦à¦•à¦¸à¦¾à¦¥à§‡à¥¤

---

## ðŸ§  à¦à¦• à¦²à¦¾à¦‡à¦¨à§‡ à¦®à§‚à¦² à¦ªà¦¾à¦°à§à¦¥à¦•à§à¦¯

* **K-Means** â†’ à¦†à¦—à§‡ à¦¥à§‡à¦•à§‡à¦‡ **K à¦œà¦¾à¦¨à¦¾** à¦²à¦¾à¦—à§‡, centroid à¦§à¦°à§‡ **à¦¦à§à¦°à§à¦¤** cluster à¦¬à¦¾à¦¨à¦¾à§Ÿ
* **Hierarchical** â†’ **K à¦¨à¦¾ à¦œà§‡à¦¨à§‡à¦“** à¦šà¦²à§‡, tree (dendrogram) à¦¬à¦¾à¦¨à¦¿à§Ÿà§‡ **à¦§à¦¾à¦ªà§‡ à¦§à¦¾à¦ªà§‡** cluster à¦¦à§‡à¦–à¦¾à§Ÿ

---

## 1ï¸âƒ£ à¦•à¦¾à¦œà§‡à¦° à¦§à¦°à¦¨ (How they work)

### ðŸ”¹ K-Means

1. Kà¦Ÿà¦¾ centroid à¦¬à¦¸à¦¾à§Ÿ
2. à¦ªà§à¦°à¦¤à¦¿à¦Ÿà¦¾ point â†’ nearest centroid
3. centroid = mean (à¦—à§œ)
4. repeat â†’ converge

ðŸ‘‰ à¦²à¦•à§à¦·à§à¦¯: **WCSS (inertia) minimize**

---

### ðŸ”¹ Hierarchical (Agglomerative)

1. à¦¶à§à¦°à§à¦¤à§‡ à¦ªà§à¦°à¦¤à¦¿à¦Ÿà¦¾ point = à¦†à¦²à¦¾à¦¦à¦¾ cluster
2. à¦¸à¦¬à¦šà§‡à§Ÿà§‡ à¦•à¦¾à¦›à§‡à¦° cluster **merge**
3. à¦§à¦¾à¦ªà§‡ à¦§à¦¾à¦ªà§‡ merge à¦•à¦°à§‡ **tree (dendrogram)** à¦¬à¦¾à¦¨à¦¾à§Ÿ
4. à¦¯à§‡à¦•à§‹à¦¨à§‹ height-à¦ cut à¦•à¦°à§‡ cluster à¦¨à¦¿à¦¨

ðŸ‘‰ à¦²à¦•à§à¦·à§à¦¯: **Hierarchy à¦¬à§‹à¦à¦¾ + structure à¦–à§‹à¦à¦œà¦¾**

---

## 2ï¸âƒ£ K à¦œà¦¾à¦¨à¦¾ à¦²à¦¾à¦—à§‡?

| à¦¬à¦¿à¦·à§Ÿ            | K-Means             | Hierarchical     |
| --------------- | ------------------- | ---------------- |
| à¦†à¦—à§‡ K à¦¦à¦¿à¦¤à§‡ à¦¹à§Ÿ?  | âœ… à¦¹à§à¦¯à¦¾à¦             | âŒ à¦¨à¦¾             |
| à¦ªà¦°à§‡ K à¦¬à¦¾à¦›à¦¾ à¦¯à¦¾à§Ÿ? | âš ï¸ Elbow/Silhouette | âœ… Dendrogram cut |

---

## 3ï¸âƒ£ Output à¦•à§‡à¦®à¦¨?

* **K-Means** â†’ Flat clusters (à¦¶à§à¦§à§ final group)
* **Hierarchical** â†’ Tree + à¦¸à¦¬ level-à¦à¦° clusters

---

## 4ï¸âƒ£ Speed & Scale

| à¦¦à¦¿à¦•              | K-Means     | Hierarchical |
| ---------------- | ----------- | ------------ |
| à¦¬à§œ dataset       | âœ… à¦–à§à¦¬ à¦¦à§à¦°à§à¦¤ | âŒ à¦§à§€à¦°        |
| Memory           | à¦•à¦®          | à¦¬à§‡à¦¶à¦¿         |
| Online/iterative | à¦¸à¦®à§à¦­à¦¬       | à¦¨à¦¾           |

---

## 5ï¸âƒ£ Cluster shape à¦“ robustness

| à¦¬à¦¿à¦·à§Ÿ                | K-Means               | Hierarchical    |
| ------------------- | --------------------- | --------------- |
| Shape               | à¦—à§‹à¦²à¦¾à¦•à¦¾à¦° (spherical)   | Flexible        |
| Outlier sensitivity | à¦¬à§‡à¦¶à¦¿                  | linkage à¦…à¦¨à§à¦¯à¦¾à§Ÿà§€ |
| Initialization      | sensitive (K-Means++) | deterministic   |

---

## 6ï¸âƒ£ Explainability

* **K-Means**: à¦•à§‡à¦¨ cluster à¦¹à¦²à§‹â€”à¦¬à§‹à¦à¦¾ à¦•à¦ à¦¿à¦¨
* **Hierarchical**: dendrogram à¦¦à§‡à¦–à§‡ **à¦•à§‡à¦¨/à¦•à¦¿à¦­à¦¾à¦¬à§‡ merge**â€”à¦¸à¦¹à¦œà§‡ explain à¦•à¦°à¦¾ à¦¯à¦¾à§Ÿ

---

## 7ï¸âƒ£ à¦•à¦–à¦¨ à¦•à§‹à¦¨à¦Ÿà¦¾ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à¦¬à§‡à¦¨?

### âœ… K-Means à¦¨à¦¿à¦¨ à¦¯à¦–à¦¨:

* Dataset à¦¬à§œ
* K à¦¸à¦®à§à¦ªà¦°à§à¦•à§‡ à¦§à¦¾à¦°à¦£à¦¾ à¦†à¦›à§‡
* Speed à¦¦à¦°à¦•à¦¾à¦°
* Real-time/production use

### âœ… Hierarchical à¦¨à¦¿à¦¨ à¦¯à¦–à¦¨:

* Dataset à¦›à§‹à¦Ÿ/à¦®à¦¾à¦à¦¾à¦°à¦¿
* K à¦œà¦¾à¦¨à¦¾ à¦¨à§‡à¦‡
* Structure/relationship à¦¬à§‹à¦à¦¾ à¦¦à¦°à¦•à¦¾à¦°
* Explainability à¦—à§à¦°à§à¦¤à§à¦¬à¦ªà§‚à¦°à§à¦£ (bio, text, similarity)

---

## 8ï¸âƒ£ à¦›à§‹à¦Ÿ à¦¬à¦¾à¦¸à§à¦¤à¦¬ à¦‰à¦¦à¦¾à¦¹à¦°à¦£

* **Customer segmentation (à§§M user)** â†’ **K-Means**
* **Gene similarity / document similarity** â†’ **Hierarchical**
* **Exploration + final clustering** â†’ Hierarchical â†’ K-Means

---

## ðŸ“Š à¦à¦• à¦¨à¦œà¦°à§‡ à¦¤à§à¦²à¦¨à¦¾ (Cheat Sheet)

| Feature        | K-Means      | Hierarchical |
| -------------- | ------------ | ------------ |
| Learning       | Unsupervised | Unsupervised |
| Need K         | Yes          | No           |
| Output         | Flat         | Tree         |
| Speed          | Fast         | Slow         |
| Explainability | Low          | High         |
| Best for       | Large data   | Small/EDA    |

---

## ðŸ”‘ Exam / Interview One-liner

> **K-Means is a centroid-based clustering method that requires K beforehand and scales well, whereas hierarchical clustering builds a tree of clusters without needing K in advance and offers better interpretability.**

---

