![Image](https://miro.medium.com/v2/resize%3Afit%3A1400/1%2AigBfOi1IFWA_H3aNZG0bzQ.png)

![Image](https://towardsdatascience.com/wp-content/uploads/2022/11/1OE9JOSlm7yViIQMz-hsN2Q.png)

![Image](https://codesignal-staging-assets.s3.amazonaws.com/uploads/1712684902890/plot-centroids.png)

![Image](https://miro.medium.com/v2/resize%3Afit%3A1400/1%2AJWcn7KOZiMgMlNA6tDJjhA.png)

## âš ï¸ **Random Initialization Trap** & âœ… **K-Means++** â€” à¦¸à¦¹à¦œ à¦œà§à¦¯à¦¾à¦®à¦¿à¦¤à¦¿à¦• à¦¬à§à¦¯à¦¾à¦–à§à¦¯à¦¾

---

## ðŸ§  à¦¸à¦®à¦¸à§à¦¯à¦¾à¦Ÿà¦¾ à¦•à§€? (Random Initialization Trap)

**K-Means** à¦¶à§à¦°à§à¦¤à§‡à¦‡ centroid à¦—à§à¦²à§‹ **random** à¦¬à¦¸à¦¾à§Ÿà¥¤
à¦à¦‡ random à¦¶à§à¦°à§à¦Ÿà¦¾à¦‡ à¦…à¦¨à§‡à¦• à¦¸à¦®à§Ÿ **à¦­à§à¦² à¦œà¦¾à§Ÿà¦—à¦¾à§Ÿ à¦†à¦Ÿà¦•à§‡ à¦«à§‡à¦²à§‡** (trap)à¥¤

### à¦•à§‡à¦¨ trap à¦¹à§Ÿ?

* à¦¶à§à¦°à§à¦¤à§‡ centroid à¦­à§à¦² à¦œà¦¾à§Ÿà¦—à¦¾à§Ÿ à¦¬à¦¸à¦²à§‡
* algorithm **à¦–à¦¾à¦°à¦¾à¦ª local minimum**-à¦ converge à¦•à¦°à§‡
* à¦«à¦²à¦¾à¦«à¦²:

  * à¦­à§à¦² cluster
  * à¦¬à§‡à¦¶à¦¿ WCSS (inertia)
  * run-to-run à¦­à¦¿à¦¨à§à¦¨ à¦«à¦²

---

## ðŸ”´ Random Initialization Trap â€” à¦¸à¦¹à¦œ à¦‰à¦¦à¦¾à¦¹à¦°à¦£

à¦§à¦°à¦¾ à¦¯à¦¾à¦• 2D-à¦¤à§‡ **à§©à¦Ÿà¦¾ natural cluster** à¦†à¦›à§‡à¥¤

### à¦–à¦¾à¦°à¦¾à¦ª random à¦¶à§à¦°à§:

* 2à¦Ÿà¦¾ centroid à¦à¦•à¦‡ cluster-à¦à¦° à¦­à§‡à¦¤à¦°à§‡
* à¦†à¦°à§‡à¦•à¦Ÿà¦¾ centroid à¦…à¦¨à§‡à¦• à¦¦à§‚à¦°à§‡

à¦«à¦²:

* à¦à¦• cluster à¦¦à§à¦‡ à¦­à¦¾à¦—
* à¦…à¦¨à§à¦¯ cluster merge
* algorithm â€œà¦ à¦¿à¦•â€ à¦¹à¦¤à§‡ à¦ªà¦¾à¦°à§‡ à¦¨à¦¾

ðŸ“Œ à¦•à¦¾à¦°à¦£ K-Means à¦¶à§à¦§à§ **local move (mean update)** à¦•à¦°à§‡â€”à¦ªà§‡à¦›à¦¨à§‡ à¦«à¦¿à¦°à§‡ global à¦ à¦¿à¦• à¦•à¦°à§‡ à¦¨à¦¾à¥¤

---

## â“ à¦•à§‡à¦¨ K-Means à¦¨à¦¿à¦œà§‡ à¦ à¦¿à¦• à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à§‡ à¦¨à¦¾?

K-Means minimize à¦•à¦°à§‡:

> **Within-Cluster Sum of Squares (WCSS)**

à¦•à¦¿à¦¨à§à¦¤à§ à¦à¦Ÿà¦¾:

* **non-convex** problem
* à¦…à¦¨à§‡à¦• local minimum à¦†à¦›à§‡

ðŸ‘‰ à¦¶à§à¦°à§à¦Ÿà¦¾ à¦–à¦¾à¦°à¦¾à¦ª à¦¹à¦²à§‡ à¦¶à§‡à¦·à¦“ à¦–à¦¾à¦°à¦¾à¦ª à¦¹à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¥¤

---

## âœ… à¦¸à¦®à¦¾à¦§à¦¾à¦¨: **K-Means++**

**K-Means++** à¦¹à¦²à§‹ smarter initialization strategy
ðŸ‘‰ random à¦¨à§Ÿ, **distance-aware**à¥¤

---

## ðŸ§  K-Means++ â€” à¦à¦• à¦²à¦¾à¦‡à¦¨à§‡à¦° à¦†à¦‡à¦¡à¦¿à§Ÿà¦¾

> **Centroid à¦à¦®à¦¨à¦­à¦¾à¦¬à§‡ à¦¬à¦¸à¦¾à¦“ à¦¯à§‡à¦¨ à¦¤à¦¾à¦°à¦¾ à¦à¦•à§‡ à¦…à¦ªà¦° à¦¥à§‡à¦•à§‡ à¦¯à¦¤à¦Ÿà¦¾ à¦¸à¦®à§à¦­à¦¬ à¦¦à§‚à¦°à§‡ à¦¥à¦¾à¦•à§‡à¥¤**

---

## ðŸ§© K-Means++ Step-by-Step (Intuition)

### ðŸ”¹ Step 1: à¦ªà§à¦°à¦¥à¦® centroid

* à¦¡à§‡à¦Ÿà¦¾ à¦¥à§‡à¦•à§‡ **random** à¦à¦•à¦Ÿà¦¾ point à¦¨à¦¾à¦“

(à¦à¦Ÿà¦¾ unavoidable)

---

### ðŸ”¹ Step 2: Distance à¦¹à¦¿à¦¸à¦¾à¦¬

* à¦ªà§à¦°à¦¤à¦¿à¦Ÿà¦¾ point à¦¥à§‡à¦•à§‡
* **à¦¸à¦¬à¦šà§‡à§Ÿà§‡ à¦•à¦¾à¦›à§‡à¦° centroid** à¦ªà¦°à§à¦¯à¦¨à§à¦¤ distanceÂ² à¦¬à§‡à¦° à¦•à¦°à§‹

---

### ðŸ”¹ Step 3: Probability à¦¦à¦¿à§Ÿà§‡ à¦¨à¦¤à§à¦¨ centroid

* à¦¯à§‡à¦¸à¦¬ point centroid à¦¥à§‡à¦•à§‡ **à¦¦à§‚à¦°à§‡**,
* à¦¤à¦¾à¦¦à§‡à¦° **centroid à¦¹à¦“à§Ÿà¦¾à¦° chance à¦¬à§‡à¦¶à¦¿**

[
P(x) \propto D(x)^2
]

ðŸ‘‰ à¦¦à§‚à¦°à§‡à¦° cluster à¦†à¦—à§‡ à¦§à¦°à¦¾ à¦ªà§œà§‡

---

### ðŸ”¹ Step 4: Repeat

* à¦¯à¦¤à¦•à§à¦·à¦£ à¦¨à¦¾ Kà¦Ÿà¦¾ centroid à¦ªà¦¾à¦“à§Ÿà¦¾ à¦¯à¦¾à§Ÿ

---

### ðŸ”¹ Step 5: Normal K-Means run

* Assignment â†’ Update â†’ Converge

---

## ðŸ“ Geometry à¦¦à¦¿à§Ÿà§‡ à¦¬à§‹à¦à¦¾

* Random init â†’ centroid à¦—à§à¦²à§‹ à¦—à¦¾à¦¦à¦¾à¦—à¦¾à¦¦à¦¿
* K-Means++ â†’ centroid à¦—à§à¦²à§‹ **space à¦œà§à§œà§‡ à¦›à§œà¦¿à§Ÿà§‡ à¦ªà§œà§‡**

ðŸ‘‰ à¦¶à§à¦°à§à¦¤à§‡à¦‡ **à¦­à¦¾à¦²à§‹ coverage**

---

## ðŸ” à¦›à§‹à¦Ÿ Numeric Intuition (1D)

Data:

```
[1, 2, 3, 50, 51, 52]
K = 2
```

### Random init:

* Centroids: 2, 3 âŒ
  â†’ à¦¬à§œ group miss

### K-Means++:

* First: 2
* Far point (â‰ˆ50) gets high probability
  â†’ Second centroid â‰ˆ 50 âœ…

ðŸ‘‰ Perfect start

---

## ðŸ“Š Random vs K-Means++ (à¦à¦• à¦¨à¦œà¦°à§‡)

| à¦¬à¦¿à¦·à§Ÿ              | Random Init          | K-Means++      |
| ----------------- | -------------------- | -------------- |
| Start quality     | Unstable             | Stable         |
| Local minima      | à¦¬à§‡à¦¶à¦¿                 | à¦•à¦®             |
| WCSS              | à¦¬à§‡à¦¶à¦¿ à¦¹à¦¤à§‡ à¦ªà¦¾à¦°à§‡        | à¦•à¦®             |
| Speed             | à¦§à§€à¦° (restarts à¦¦à¦°à¦•à¦¾à¦°) | à¦¦à§à¦°à§à¦¤ converge |
| Default (sklearn) | âŒ                    | âœ…              |

---

## âš™ï¸ à¦¬à¦¾à¦¸à§à¦¤à¦¬à§‡ à¦•à§€ à¦•à¦°à¦¬à§‡à¦¨?

### Best practice:

* **K-Means++ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§à¦¨**
* à¦…à¦¥à¦¬à¦¾:

  * random init + à¦…à¦¨à§‡à¦•à¦¬à¦¾à¦° run (n_init â†‘)

ðŸ“Œ sklearn default:

```python
KMeans(init="k-means++", n_init=10)
```

---

## ðŸ”‘ Golden Sentence (Exam / Interview)

> **Random initialization can trap K-Means in poor local minima; K-Means++ mitigates this by initializing centroids far apart using a distance-based probability.**

---

