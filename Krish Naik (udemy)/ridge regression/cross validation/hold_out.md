# Hold-Out Validation

Hold-Out Validation рж╕рж╛ржзрж╛рж░ржгржд рждржЦржи ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ рж╣ржпрж╝ ржпржЦржи ржбрзЗржЯрж╛рж╕рзЗржЯ ржмржбрж╝ ржЖржХрж╛рж░рзЗрж░ ржПржмржВ ржЖржорж░рж╛ ржжрзНрж░рзБржд ржоржбрзЗрж▓ ржЯрзНрж░рзЗржи ржУ ржЯрзЗрж╕рзНржЯ ржХрж░рждрзЗ ржЪрж╛ржЗред

---

## ЁЯУМ ржХржЦржи ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ рж╣ржпрж╝ (Examples):

### рзз. ржкрзНрж░рж╛ржержорж┐ржХ ржоржбрзЗрж▓ ржЯрзЗрж╕рзНржЯ ржХрж░рж╛рж░ ржЬржирзНржп

ржпржЦржи ржЖржкржирж┐ ржирждрзБржи ржПржХржЯрж┐ ржЕрзНржпрж╛рж▓ржЧрж░рж┐ржжржо ржЯрзНрж░рж╛ржЗ ржХрж░ржЫрзЗржи ржПржмржВ ржжрзНрж░рзБржд ржЬрж╛ржирждрзЗ ржЪрж╛ржи ржоржбрзЗрж▓ ржХрж╛ржЬ ржХрж░ржЫрзЗ ржХрж┐ржирж╛ред

**ржЙржжрж╛рж╣рж░ржг:** ржПржХржЯрж┐ Spam Detection Model ржП ржЗржорзЗржЗрж▓ ржбрзЗржЯрж╛ржХрзЗ рзорзж% Train ржПржмржВ рзирзж% Test ржП ржнрж╛ржЧ ржХрж░рзЗ ржкрзНрж░ржержоржмрж╛рж░ ржоржбрзЗрж▓рзЗрж░ accuracy ржжрзЗржЦрж╛ред

```python
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

# ржбрзЗржЯрж╛ split ржХрж░рж╛
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ржоржбрзЗрж▓ ржЯрзНрж░рзЗржи ржХрж░рж╛
model = MultinomialNB()
model.fit(X_train, y_train)

# ржкрзНрж░рзЗржбрж┐ржХрж╢ржи ржУ accuracy
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Spam Detection Accuracy: {accuracy:.2f}")
```

---

### рзи. ржмржбрж╝ ржбрзЗржЯрж╛рж╕рзЗржЯрзЗрж░ ржХрзНрж╖рзЗрждрзНрж░рзЗ

ржпржжрж┐ ржбрзЗржЯрж╛рж╕рзЗржЯ ржЕржирзЗржХ ржмржбрж╝ рж╣ржпрж╝ (ржпрзЗржоржи: рж▓рж╛ржЦ рж▓рж╛ржЦ рж░рзЗржХрж░рзНржб), рждржЦржи Hold-Out ржпржерзЗрж╖рзНржЯред

**ржХрж╛рж░ржг:** ржПржоржиржХрж┐ рзирзж% ржбрзЗржЯрж╛ржУ ржЯрзЗрж╕рзНржЯ ржХрж░рж╛рж░ ржЬржирзНржп ржпржерзЗрж╖рзНржЯ ржмржбрж╝ред

**ржЙржжрж╛рж╣рж░ржг:** Netflix movie recommendation system ржПрж░ ржЬржирзНржп ржмрж┐рж╢рж╛рж▓ ржбрзЗржЯрж╛ ржерж╛ржХрж▓рзЗ hold-out ржХрж░рж╛ рж╣ржпрж╝ред

```python
# ржмржбрж╝ ржбрзЗржЯрж╛рж╕рзЗржЯрзЗрж░ ржЬржирзНржп
print(f"Total dataset size: {len(X):,} samples")
print(f"Training set: {len(X_train):,} samples")
print(f"Test set: {len(X_test):,} samples")

# ржпржжрж┐ рззрзж рж▓рж╛ржЦ ржбрзЗржЯрж╛ ржерж╛ржХрзЗ:
# Training: рзо рж▓рж╛ржЦ
# Testing: рзи рж▓рж╛ржЦ (ржпржерзЗрж╖рзНржЯ ржмржбрж╝ ржЯрзЗрж╕рзНржЯ рж╕рзЗржЯ)
```

---

### рзй. ржоржбрзЗрж▓рзЗрж░ ржжрзНрж░рзБржд Benchmark рждрзИрж░рж┐ ржХрж░рждрзЗ

ржЧржмрзЗрж╖ржХрж░рж╛ ржпржЦржи ржПржХрж╛ржзрж┐ржХ ржоржбрзЗрж▓ рждрзБрж▓ржирж╛ ржХрж░рзЗржи, рждржЦржи ржПржХржЯрж┐ ржирж┐рж░рзНржжрж┐рж╖рзНржЯ hold-out split ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ performance рждрзБрж▓ржирж╛ ржХрж░рзЗржиред

**ржЙржжрж╛рж╣рж░ржг:** Decision Tree, Logistic Regression ржЖрж░ Random Forest ржПрж░ accuracy рждрзБрж▓ржирж╛ ржХрж░рж╛ред

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# ржПржХржЗ train-test split ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржоржбрзЗрж▓ рждрзБрж▓ржирж╛
models = {
    'Decision Tree': DecisionTreeClassifier(),
    'Logistic Regression': LogisticRegression(),
    'Random Forest': RandomForestClassifier()
}

results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    results[name] = accuracy
    print(f"{name}: {accuracy:.3f}")

# ржлрж▓рж╛ржлрж▓:
# Decision Tree: 0.845
# Logistic Regression: 0.892
# Random Forest: 0.918
```

---

### рзк. Time ржмрж╛ Computation ржХржорж╛рждрзЗ

**K-Fold cross validation** ржП ржоржбрзЗрж▓ржХрзЗ ржПржХрж╛ржзрж┐ржХржмрж╛рж░ ржЯрзНрж░рзЗржи ржХрж░рждрзЗ рж╣ржпрж╝ред

ржХрж┐ржирзНрждрзБ **Hold-Out** ржП рж╢рзБржзрзБ ржПржХржмрж╛рж░ ржЯрзНрж░рзЗржи ржХрж░рждрзЗ рж╣ржпрж╝ред

рждрж╛ржЗ ржпржЦржи рж╕ржоржпрж╝ ржмрж╛ ржХржорзНржкрж┐ржЙржЯрзЗрж╢ржирзЗрж░ рж╕рзАржорж╛ржмржжрзНржзрждрж╛ ржерж╛ржХрзЗ рждржЦржи ржПржЯрж┐ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ рж╣ржпрж╝ред

```python
import time

# Hold-Out Validation (ржжрзНрж░рзБржд)
start_time = time.time()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
holdout_time = time.time() - start_time

print(f"Hold-Out time: {holdout_time:.2f} seconds")

# K-Fold ржПрж░ рждрзБрж▓ржирж╛ржпрж╝ ржЕржирзЗржХ ржХржо рж╕ржоржпрж╝ рж▓рж╛ржЧрзЗ
```

---

## ЁЯЪА ржЙржжрж╛рж╣рж░ржг (ржмрж╛рж╕рзНрждржм ржЬрзАржмржи Scenario):

### тЬЕ ржорзЗржбрж┐ржХрзЗрж▓ ржбрзЗржЯрж╛рж╕рзЗржЯ (ржбрж╛ржпрж╝рж╛ржмрзЗржЯрж┐рж╕ ржкрзНрж░рзЗржбрж┐ржХрж╢ржи)

ржЖржкржирж╛рж░ ржХрж╛ржЫрзЗ рзз,рзжрзж,рзжрзжрзж рж░рзЛржЧрзАрж░ рждржерзНржп ржЖржЫрзЗред

ржЖржкржирж┐ рзорзж,рзжрзжрзж ржбрзЗржЯрж╛ ржжрж┐ржпрж╝рзЗ ржоржбрзЗрж▓ ржЯрзНрж░рзЗржи ржХрж░рж▓рзЗржи, ржмрж╛ржХрж┐ рзирзж,рзжрзжрзж ржбрзЗржЯрж╛ржпрж╝ ржЯрзЗрж╕рзНржЯ ржХрж░рж▓рзЗржиред

ржПрждрзЗ ржмрзЛржЭрж╛ ржпрж╛ржмрзЗ ржоржбрзЗрж▓ ржмрж╛рж╕рзНрждржм ржЬрзАржмржирзЗ ржХрждржЯрж╛ рж╕ржарж┐ржХржнрж╛ржмрзЗ ржХрж╛ржЬ ржХрж░рждрзЗ ржкрж╛рж░рзЗред

```python
from sklearn.datasets import load_diabetes
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# ржбрж╛ржпрж╝рж╛ржмрзЗржЯрж┐рж╕ ржбрзЗржЯрж╛рж╕рзЗржЯ рж▓рзЛржб
diabetes = load_diabetes()
X, y = diabetes.data, diabetes.target

# рзорзж-рзирзж split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ржоржбрзЗрж▓ ржЯрзНрж░рзЗржЗржирж┐ржВ
model = LinearRegression()
model.fit(X_train, y_train)

# ржЯрзЗрж╕рзНржЯ рж╕рзЗржЯрзЗ ржкрзНрж░рзЗржбрж┐ржХрж╢ржи
y_pred = model.predict(X_test)

# ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржорзЗржЯрзНрж░рж┐ржХрзНрж╕
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Training samples: {len(X_train):,}")
print(f"Test samples: {len(X_test):,}")
print(f"Mean Squared Error: {mse:.2f}")
print(f"R┬▓ Score: {r2:.3f}")
```

---

### тЬЕ ржЗ-ржХржорж╛рж░рзНрж╕ Recommendation

Amazon ржпржжрж┐ ржкржгрзНржпрзЗрж░ ржбрзЗржЯрж╛ ржирж┐ржпрж╝рзЗ ржХрж╛ржЬ ржХрж░рзЗ, рждрж╛рж╣рж▓рзЗ рждрж╛рж░рж╛ ржбрзЗржЯрж╛рж░ ржПржХржЯрж┐ ржЕржВрж╢ hold-out ржХрж░рзЗ рж░рж╛ржЦрзЗ, ржпрж╛рждрзЗ ржоржбрзЗрж▓ ржЖржЧрзЗ ржжрзЗржЦрж╛ ржирж╛ ржХрж░рж╛ ржбрзЗржЯрж╛ржпрж╝ ржХрзЗржоржи ржХрж╛ржЬ ржХрж░ржЫрзЗ рждрж╛ ржмрзЛржЭрж╛ ржпрж╛ржпрж╝ред

```python
# ржЗ-ржХржорж╛рж░рзНрж╕ recommendation example
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ржкржгрзНржпрзЗрж░ ржмрж┐ржмрж░ржг (dummy data)
products = [
    "Smartphone with camera",
    "Laptop computer gaming",
    "Wireless headphones music",
    "Camera photography digital",
    "Gaming mouse wireless"
]

# Hold-out strategy: ржирждрзБржи ржкржгрзНржпрзЗрж░ ржЬржирзНржп ржЖрж▓рж╛ржжрж╛ ржЯрзЗрж╕рзНржЯ рж╕рзЗржЯ
train_products = products[:4]  # Training data
test_product = products[4:]    # Test data (ржирждрзБржи ржкржгрзНржп)

# TF-IDF vectorization
vectorizer = TfidfVectorizer()
train_vectors = vectorizer.fit_transform(train_products)
test_vector = vectorizer.transform(test_product)

# Similarity calculation
similarities = cosine_similarity(test_vector, train_vectors)
print("Product similarities:", similarities[0])

# рж╕ржмржЪрзЗржпрж╝рзЗ ржХрж╛ржЫрж╛ржХрж╛ржЫрж┐ ржкржгрзНржп ржЦрзБржБржЬрзЗ ржмрзЗрж░ ржХрж░рж╛
most_similar_idx = similarities[0].argmax()
print(f"Most similar product: {train_products[most_similar_idx]}")
```

---

## ЁЯУК Hold-Out Validation ржПрж░ рж╕рзБржмрж┐ржзрж╛ ржУ ржЕрж╕рзБржмрж┐ржзрж╛

### тЬЕ рж╕рзБржмрж┐ржзрж╛:
1. **ржжрзНрж░рзБржд Execution:** ржПржХржмрж╛рж░ржЗ ржоржбрзЗрж▓ ржЯрзНрж░рзЗржи ржХрж░рждрзЗ рж╣ржпрж╝
2. **рж╕рж╣ржЬ Implementation:** ржХрзЛржб рж▓рж┐ржЦрждрзЗ рж╕рж╣ржЬ
3. **Memory Efficient:** ржХржо ржорзЗржорзЛрж░рж┐ ржмрзНржпржмрж╣рж╛рж░
4. **ржмржбрж╝ ржбрзЗржЯрж╛рж╕рзЗржЯрзЗ ржХрж╛рж░рзНржпржХрж░:** ржпржерзЗрж╖рзНржЯ ржбрзЗржЯрж╛ ржерж╛ржХрж▓рзЗ reliable

### тЭМ ржЕрж╕рзБржмрж┐ржзрж╛:
1. **Data Split Dependency:** ржбрзЗржЯрж╛ ржХрзАржнрж╛ржмрзЗ ржнрж╛ржЧ рж╣рж▓рзЛ рждрж╛рж░ ржЙржкрж░ ржирж┐рж░рзНржнрж░рж╢рзАрж▓
2. **High Variance:** ржмрж┐ржнрж┐ржирзНржи split ржП ржмрж┐ржнрж┐ржирзНржи ржлрж▓рж╛ржлрж▓
3. **Data Waste:** ржХрж┐ржЫрзБ ржбрзЗржЯрж╛ рж╢рзБржзрзБ testing ржП ржмрзНржпржмрж╣рзГржд рж╣ржпрж╝
4. **ржЫрзЛржЯ ржбрзЗржЯрж╛рж╕рзЗржЯрзЗ рж╕ржорж╕рзНржпрж╛:** ржкрж░рзНржпрж╛ржкрзНржд training data ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржпрж╝ ржирж╛

---

## ЁЯОп ржХржЦржи Hold-Out ржмрзНржпржмрж╣рж╛рж░ ржХрж░ржмрзЗржи?

### тЬЕ ржЙржкржпрзБржХрзНржд ржкрж░рж┐рж╕рзНржерж┐рждрж┐:
- **ржмржбрж╝ ржбрзЗржЯрж╛рж╕рзЗржЯ** (>10,000 samples)
- **ржжрзНрж░рзБржд ржкрзНрж░рзЛржЯрзЛржЯрж╛ржЗржкрж┐ржВ**
- **Initial model exploration**
- **Computational constraints**
- **Baseline model рждрзИрж░рж┐**

### тЭМ ржПржбрж╝рж┐ржпрж╝рзЗ ржЪрж▓рзБржи ржпржЦржи:
- **ржЫрзЛржЯ ржбрзЗржЯрж╛рж╕рзЗржЯ** (<1,000 samples)
- **Critical model selection**
- **Final model evaluation**
- **Research publication**
- **High-stakes applications**

---

## ЁЯЫая╕П Best Practices

### 1. **Stratified Split ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзБржи:**
```python
# Classification ржПрж░ ржЬржирзНржп
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)
```

### 2. **Random State рж╕рзЗржЯ ржХрж░рзБржи:**
```python
# Reproducible results ржПрж░ ржЬржирзНржп
train_test_split(X, y, test_size=0.2, random_state=42)
```

### 3. **Appropriate Split Ratio:**
```python
# рж╕рж╛ржзрж╛рж░ржг ржЕржирзБржкрж╛ржд:
# 80-20: рж╕ржмржЪрзЗржпрж╝рзЗ common
# 70-30: ржЫрзЛржЯ ржбрзЗржЯрж╛рж╕рзЗржЯрзЗрж░ ржЬржирзНржп
# 90-10: ржЦрзБржм ржмржбрж╝ ржбрзЗржЯрж╛рж╕рзЗржЯрзЗрж░ ржЬржирзНржп
```

### 4. **Data Leakage ржПржбрж╝рж╛ржи:**
```python
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# Preprocessing рж╢рзБржзрзБ training data ржжрж┐ржпрж╝рзЗ fit ржХрж░рзБржи
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', LinearRegression())
])

pipeline.fit(X_train, y_train)  # рж╢рзБржзрзБ training data ржжрж┐ржпрж╝рзЗ fit
y_pred = pipeline.predict(X_test)  # test data ржП predict
```

---

## ЁЯСЙ рж╕ржВржХрзНрж╖рзЗржкрзЗ:

**Hold-Out Validation** рж╣рж▓рзЛ ржкрзНрж░ржержо ржзрж╛ржкрзЗрж░ validation method тАФ ржЫрзЛржЯ ржбрзЗржЯрж╛ржпрж╝ bias ржерж╛ржХрждрзЗ ржкрж╛рж░рзЗ, ржХрж┐ржирзНрждрзБ ржмржбрж╝ ржбрзЗржЯрж╛ржпрж╝ ржжрзНрж░рзБржд ржУ ржХрж╛рж░рзНржпржХрж░ред

**ржорзВрж▓ ржирзАрждрж┐:** Simple, Fast, Effective for large datasets ржХрж┐ржирзНрждрзБ K-Fold CV ржПрж░ ржорждрзЛ robust ржиржпрж╝ред