à¦¨à¦¿à¦¶à§à¦šà¦¿à¦¤à¦­à¦¾à¦¬à§‡â€”à¦¨à¦¿à¦šà§‡ **Lemmatization.ipynb**-à¦à¦° **à¦ªà§à¦°à¦¤à¦¿à¦Ÿà¦¿ Cell-à¦à¦° à¦•à§‹à¦¡ à¦²à¦¾à¦‡à¦¨â€“à¦¬à¦¾à¦‡â€“à¦²à¦¾à¦‡à¦¨ à¦¬à¦¾à¦‚à¦²à¦¾à¦¯à¦¼ à¦¬à§à¦¯à¦¾à¦–à§à¦¯à¦¾** à¦¦à§‡à¦“à§Ÿà¦¾ à¦¹à¦²à§‹à¥¤
(à¦•à§‹à¦¨ Cell à¦•à§€ à¦•à¦¾à¦œ à¦•à¦°à¦›à§‡, à¦•à§‡à¦¨ à¦¦à¦°à¦•à¦¾à¦°â€”à¦¸à¦¬ à¦ªà¦°à¦¿à¦·à§à¦•à¦¾à¦°à¦­à¦¾à¦¬à§‡)

---

## ðŸ§© **Cell 1 â€” POS Tagger à¦¡à¦¾à¦‰à¦¨à¦²à§‹à¦¡**

```python
import nltk
nltk.download('averaged_perceptron_tagger_eng')
```

### ðŸ” à¦¬à§à¦¯à¦¾à¦–à§à¦¯à¦¾

* `import nltk`
  ðŸ‘‰ NLTK à¦²à¦¾à¦‡à¦¬à§à¦°à§‡à¦°à¦¿ Python-à¦ à¦‡à¦®à¦ªà§‹à¦°à§à¦Ÿ à¦•à¦°à¦¾ à¦¹à¦šà§à¦›à§‡à¥¤

* `nltk.download('averaged_perceptron_tagger_eng')`
  ðŸ‘‰ **POS Tagger model** à¦¡à¦¾à¦‰à¦¨à¦²à§‹à¦¡ à¦•à¦°à¦¾ à¦¹à¦šà§à¦›à§‡à¥¤
  ðŸ‘‰ à¦à¦Ÿà¦¿ à¦¶à¦¬à§à¦¦à§‡à¦° **Part of Speech (Noun, Verb, Adjective à¦‡à¦¤à§à¦¯à¦¾à¦¦à¦¿)** à¦¶à¦¨à¦¾à¦•à§à¦¤ à¦•à¦°à¦¤à§‡ à¦¬à§à¦¯à¦¬à¦¹à§ƒà¦¤ à¦¹à§Ÿà¥¤

ðŸ“Œ **à¦•à§‡à¦¨ à¦¦à¦°à¦•à¦¾à¦°?**
Lemmatization-à¦ à¦¸à¦ à¦¿à¦• à¦«à¦² à¦ªà§‡à¦¤à§‡ à¦¹à¦²à§‡ POS à¦œà¦¾à¦¨à¦¾ à¦œà¦°à§à¦°à¦¿à¥¤

---

## ðŸ§© **Cell 2 â€” à¦ªà§à¦°à§Ÿà§‹à¦œà¦¨à§€à§Ÿ NLTK Resources à¦¡à¦¾à¦‰à¦¨à¦²à§‹à¦¡**

```python
import nltk
# à¦ªà§à¦°à¦¥à¦®à¦¬à¦¾à¦° à¦šà¦¾à¦²à¦¾à¦²à§‡
nltk.download("wordnet")
nltk.download("omw-1.4")
nltk.download("punkt")
nltk.download("averaged_perceptron_tagger")
```

### ðŸ” à¦¬à§à¦¯à¦¾à¦–à§à¦¯à¦¾

* `wordnet`
  ðŸ‘‰ English dictionary database
  ðŸ‘‰ Lemmatization-à¦à¦° à¦®à§‚à¦² à¦­à¦¿à¦¤à§à¦¤à¦¿

* `omw-1.4`
  ðŸ‘‰ WordNet-à¦à¦° supporting multilingual data
  ðŸ‘‰ Lemma accuracy à¦¬à¦¾à§œà¦¾à§Ÿ

* `punkt`
  ðŸ‘‰ **Tokenization** (sentence â†’ words) à¦•à¦°à¦¾à¦° à¦œà¦¨à§à¦¯

* `averaged_perceptron_tagger`
  ðŸ‘‰ POS tagging-à¦à¦° à¦œà¦¨à§à¦¯ à¦¬à§à¦¯à¦¬à¦¹à§ƒà¦¤ model

ðŸ“Œ **à¦¨à§‹à¦Ÿ:**
à¦à¦‡ Cell à¦¸à¦¾à¦§à¦¾à¦°à¦£à¦¤ **à¦à¦•à¦¬à¦¾à¦°à¦‡** à¦šà¦¾à¦²à¦¾à¦¤à§‡ à¦¹à§Ÿ (first-time setup)à¥¤

---

## ðŸ§© **Cell 3 â€” Basic Lemmatization (POS à¦›à¦¾à§œà¦¾)**

```python
from nltk.stem import WordNetLemmatizer

lemmatizer = WordNetLemmatizer()
words = ["running", "studies", "better", "mice", "cars"]

for w in words:
    print(w, "â†’", lemmatizer.lemmatize(w))
```

### ðŸ” à¦¬à§à¦¯à¦¾à¦–à§à¦¯à¦¾ (à¦²à¦¾à¦‡à¦¨ à¦§à¦°à§‡)

* `from nltk.stem import WordNetLemmatizer`
  ðŸ‘‰ Lemmatizer à¦•à§à¦²à¦¾à¦¸ à¦‡à¦®à¦ªà§‹à¦°à§à¦Ÿ à¦•à¦°à¦¾ à¦¹à¦šà§à¦›à§‡à¥¤

* `lemmatizer = WordNetLemmatizer()`
  ðŸ‘‰ Lemmatizer-à¦à¦° à¦à¦•à¦Ÿà¦¿ object à¦¤à§ˆà¦°à¦¿ à¦•à¦°à¦¾ à¦¹à¦²à§‹à¥¤

* `words = [...]`
  ðŸ‘‰ à¦¯à§‡à¦¸à¦¬ à¦¶à¦¬à§à¦¦à§‡ Lemmatization à¦•à¦°à¦¬, à¦¸à§‡à¦—à§à¦²à§‹à¦° à¦²à¦¿à¦¸à§à¦Ÿà¥¤

* `lemmatizer.lemmatize(w)`
  ðŸ‘‰ à¦ªà§à¦°à¦¤à¦¿à¦Ÿà¦¿ à¦¶à¦¬à§à¦¦à¦•à§‡ **lemma (base form)**-à¦ à¦°à§‚à¦ªà¦¾à¦¨à§à¦¤à¦° à¦•à¦°à§‡à¥¤

### ðŸ“¤ Output à¦¬à§à¦¯à¦¾à¦–à§à¦¯à¦¾

```
running â†’ running
studies â†’ study
better â†’ better
mice â†’ mouse
cars â†’ car
```

ðŸ“Œ à¦à¦–à¦¾à¦¨à§‡ `running` à¦¬à¦¦à¦²à¦¾à§Ÿà¦¨à¦¿ à¦•à¦¾à¦°à¦£
ðŸ‘‰ **default à¦¹à¦¿à¦¸à§‡à¦¬à§‡ noun à¦§à¦°à§‡ à¦¨à§‡à¦“à§Ÿà¦¾ à¦¹à§Ÿ**
ðŸ‘‰ verb à¦¹à¦²à§‡ POS à¦¦à¦¿à¦¤à§‡ à¦¹à§Ÿ

---

## ðŸ§© **Cell 4 â€” POS Mapping Function**

```python
from nltk.corpus import wordnet
from nltk import word_tokenize, pos_tag

def get_wordnet_pos(tag):
    if tag.startswith("J"):
        return wordnet.ADJ
    elif tag.startswith("V"):
        return wordnet.VERB
    elif tag.startswith("N"):
        return wordnet.NOUN
    elif tag.startswith("R"):
        return wordnet.ADV
    else:
        return wordnet.NOUN
```

### ðŸ” à¦¬à§à¦¯à¦¾à¦–à§à¦¯à¦¾

* `word_tokenize`
  ðŸ‘‰ à¦¬à¦¾à¦•à§à¦¯à¦•à§‡ à¦¶à¦¬à§à¦¦à§‡ à¦­à¦¾à¦™à§‡

* `pos_tag`
  ðŸ‘‰ à¦ªà§à¦°à¦¤à¦¿à¦Ÿà¦¿ à¦¶à¦¬à§à¦¦à§‡à¦° POS tag à¦¦à§‡à§Ÿ (NN, VB, JJ à¦‡à¦¤à§à¦¯à¦¾à¦¦à¦¿)

* `get_wordnet_pos(tag)`
  ðŸ‘‰ NLTK POS tag â†’ **WordNet POS format**-à¦ à¦°à§‚à¦ªà¦¾à¦¨à§à¦¤à¦° à¦•à¦°à§‡

### ðŸ” Mapping Logic

| NLTK Tag à¦¶à§à¦°à§ | à¦…à¦°à§à¦¥      | WordNet Tag    |
| ------------- | --------- | -------------- |
| J             | Adjective | `wordnet.ADJ`  |
| V             | Verb      | `wordnet.VERB` |
| N             | Noun      | `wordnet.NOUN` |
| R             | Adverb    | `wordnet.ADV`  |

ðŸ“Œ **à¦•à§‡à¦¨ à¦¦à¦°à¦•à¦¾à¦°?**
WordNetLemmatizer **WordNet POS** à¦šà¦¾à§Ÿ,
NLTK à¦¦à§‡à§Ÿ **short POS code**â€”à¦¤à¦¾à¦‡ mapping à¦²à¦¾à¦—à§‡à¥¤

---

## ðŸ§© **Cell 5 â€” POS à¦¸à¦¹ Lemmatization (Main Cell)**

```python
from nltk.stem import WordNetLemmatizer

lemmatizer = WordNetLemmatizer()
sentence = "The children were running better cars in London"

tokens = word_tokenize(sentence)
pos_tags = pos_tag(tokens)

lemmas = [lemmatizer.lemmatize(w, get_wordnet_pos(t)) for w, t in pos_tags]
print(lemmas)
```

### ðŸ” à¦¬à§à¦¯à¦¾à¦–à§à¦¯à¦¾ (à¦§à¦¾à¦ªà§‡ à¦§à¦¾à¦ªà§‡)

1ï¸âƒ£ `sentence = ...`
ðŸ‘‰ à¦¯à§‡à¦‡ à¦¬à¦¾à¦•à§à¦¯à¦Ÿà¦¾ preprocess à¦•à¦°à¦¬

2ï¸âƒ£ `tokens = word_tokenize(sentence)`
ðŸ‘‰ à¦¬à¦¾à¦•à§à¦¯ â†’ à¦¶à¦¬à§à¦¦

```
['The','children','were','running','better','cars','in','London']
```

3ï¸âƒ£ `pos_tags = pos_tag(tokens)`
ðŸ‘‰ à¦ªà§à¦°à¦¤à¦¿à¦Ÿà¦¿ à¦¶à¦¬à§à¦¦à§‡à¦° POS

```
('children','NNS'), ('running','VBG'), ('better','JJR') ...
```

4ï¸âƒ£ List comprehension:

```python
lemmatizer.lemmatize(w, get_wordnet_pos(t))
```

ðŸ‘‰

* à¦¶à¦¬à§à¦¦ (`w`)
* à¦¤à¦¾à¦° POS (`t`)
* POS mapping â†’ WordNet POS
* à¦¤à¦¾à¦°à¦ªà¦° **à¦¸à¦ à¦¿à¦• lemma à¦¬à§‡à¦° à¦•à¦°à¦¾**

### ðŸ“¤ Final Output

```
['The', 'child', 'be', 'run', 'good', 'car', 'in', 'London']
```

ðŸ“Œ à¦à¦–à¦¾à¦¨à§‡:

* children â†’ child
* were â†’ be
* running â†’ run
* better â†’ good

ðŸ‘‰ **à¦à¦Ÿà¦¾à¦‡ Accurate Lemmatization**

---

## ðŸ§© **Cell 6 â€” Empty Cell**

```python
```

### ðŸ” à¦¬à§à¦¯à¦¾à¦–à§à¦¯à¦¾

* à¦à¦‡ Cell à¦à¦–à¦¨à§‹ à¦–à¦¾à¦²à¦¿
* à¦¸à¦¾à¦§à¦¾à¦°à¦£à¦¤ à¦à¦–à¦¾à¦¨à§‡ à¦°à¦¾à¦–à¦¾ à¦¹à§Ÿ:

  * Extra experiment
  * Notes
  * Future code (Stopwords, Pipeline à¦‡à¦¤à§à¦¯à¦¾à¦¦à¦¿)

---

## âœ… **à¦ªà§à¦°à§‹ Notebook-à¦à¦° Flow (à¦à¦• à¦²à¦¾à¦‡à¦¨à§‡)**

```
Download resources
â†’ Tokenize sentence
â†’ POS tagging
â†’ POS mapping
â†’ Lemmatization
```

---

## ðŸ§  Exam-friendly Summary

> Lemmatization converts words into their base dictionary form using POS information, and NLTKâ€™s WordNetLemmatizer gives accurate results when POS tagging is applied.

---


