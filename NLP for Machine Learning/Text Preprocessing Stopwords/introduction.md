## ðŸ”¹ **07. Text Preprocessing: Stopwords** â€” *à¦¬à¦¾à¦‚à¦²à¦¾à¦¯à¦¼ à¦¸à¦¹à¦œ, à¦ªà¦°à§€à¦•à§à¦·à¦¾à¦®à§à¦–à§€ à¦¬à§à¦¯à¦¾à¦–à§à¦¯à¦¾ (Code + Output à¦¸à¦¹)*

![Image](https://media.geeksforgeeks.org/wp-content/cdn-uploads/Stop-word-removal-using-NLTK.png)

![Image](https://media.licdn.com/dms/image/v2/D5612AQGeJ5FET7M8lQ/article-cover_image-shrink_720_1280/B56ZebNFxzG0AI-/0/1750655621243?e=2147483647\&t=q_F45m3wtJbYY9-ARt9VZd8eZ7tsc32-JG-CqdOj9Ew\&v=beta)

![Image](https://www.researchgate.net/publication/228670007/figure/tbl2/AS%3A671525258657813%401537115506709/Sample-of-stop-words.png)

---

## ðŸ”¸ Stopwords à¦•à§€?

**Stopwords** à¦¹à¦²à§‹ à¦à¦®à¦¨ à¦¶à¦¬à§à¦¦, à¦¯à§‡à¦—à§à¦²à§‹ **à¦¬à¦¾à¦•à§à¦¯à§‡à¦° à¦…à¦°à§à¦¥ à¦¬à§‹à¦à¦¾à¦¤à§‡ à¦–à§à¦¬ à¦•à¦® à¦­à§‚à¦®à¦¿à¦•à¦¾ à¦°à¦¾à¦–à§‡**, à¦•à¦¿à¦¨à§à¦¤à§ à¦ªà§à¦°à¦¾à¦¯à¦¼ à¦¸à¦¬ à¦¬à¦¾à¦•à§à¦¯à§‡à¦‡ à¦˜à¦¨à¦˜à¦¨ à¦¬à§à¦¯à¦¬à¦¹à§ƒà¦¤ à¦¹à¦¯à¦¼à¥¤

ðŸ“Œ à¦¯à§‡à¦®à¦¨:
**the, is, are, in, on, at, and, a, an, to**

ðŸ‘‰ à¦à¦—à§à¦²à§‹ à¦¸à¦¾à¦§à¦¾à¦°à¦£à¦¤ **Text Preprocessing-à¦à¦° à¦¸à¦®à¦¯à¦¼ à¦¬à¦¾à¦¦ à¦¦à§‡à¦“à¦¯à¦¼à¦¾ à¦¹à¦¯à¦¼**à¥¤

---

## ðŸ”¸ Stopwords à¦•à§‡à¦¨ remove à¦•à¦°à¦¾ à¦¹à¦¯à¦¼?

* âœ… Noise à¦•à¦®à¦¾à¦¯à¦¼
* âœ… Vocabulary size à¦›à§‹à¦Ÿ à¦•à¦°à§‡
* âœ… Model fast à¦•à¦°à§‡
* âœ… Text classification / sentiment analysis-à¦ à¦¸à¦¾à¦¹à¦¾à¦¯à§à¦¯ à¦•à¦°à§‡

âŒ à¦•à¦¿à¦¨à§à¦¤à§ à¦¸à¦¬ à¦•à§à¦·à§‡à¦¤à§à¦°à§‡ à¦¨à¦¯à¦¼ (Chatbot / QA system-à¦ à¦¦à¦°à¦•à¦¾à¦° à¦¹à¦¤à§‡ à¦ªà¦¾à¦°à§‡)

---

## ðŸ”¹ NLTK à¦¦à¦¿à¦¯à¦¼à§‡ Stopwords Removal

à¦†à¦®à¦°à¦¾ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à¦¬ **NLTK**-à¦à¦° stopwords corpusà¥¤

---

### ðŸ”¹ Step 1: Stopwords à¦¡à¦¾à¦‰à¦¨à¦²à§‹à¦¡

```python
import nltk
# à¦ªà§à¦°à¦¥à¦®à¦¬à¦¾à¦° à¦šà¦¾à¦²à¦¾à¦²à§‡
nltk.download("stopwords")
nltk.download("punkt")
```

---

### ðŸ”¹ Step 2: Basic Stopwords Removal

```python
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

sentence = "The children were running fast in the park"

stop_words = set(stopwords.words("english"))

tokens = word_tokenize(sentence)
filtered_words = [w for w in tokens if w.lower() not in stop_words]

print("Original Tokens:", tokens)
print("After Stopwords Removal:", filtered_words)
```

### ðŸ“¤ Output

```
Original Tokens: ['The', 'children', 'were', 'running', 'fast', 'in', 'the', 'park']
After Stopwords Removal: ['children', 'running', 'fast', 'park']
```

ðŸ“Œ à¦¦à§‡à¦–à§à¦¨:

* **the, were, in** â†’ à¦¬à¦¾à¦¦ à¦—à§‡à¦›à§‡
* meaningful à¦¶à¦¬à§à¦¦à¦—à§à¦²à§‹ à¦°à¦¯à¦¼à§‡ à¦—à§‡à¦›à§‡

---

## ðŸ”¸ Stopwords Removal + Cleaning (Recommended)

```python
filtered_words = [
    w.lower() for w in tokens
    if w.isalpha() and w.lower() not in stop_words
]

print(filtered_words)
```

### ðŸ“¤ Output

```
['children', 'running', 'fast', 'park']
```

ðŸ“Œ à¦à¦–à¦¾à¦¨à§‡:

* lowercase à¦•à¦°à¦¾ à¦¹à§Ÿà§‡à¦›à§‡
* punctuation à¦¬à¦¾à¦¦ à¦—à§‡à¦›à§‡

---

## ðŸ”¸ Custom Stopwords (à¦¨à¦¿à¦œà§‡à¦° à¦®à¦¤à§‹ à¦•à¦°à§‡)

```python
custom_stopwords = stop_words.union({"fast", "park"})

filtered_words = [
    w.lower() for w in tokens
    if w.lower() not in custom_stopwords
]

print(filtered_words)
```

### ðŸ“¤ Output

```
['children', 'running']
```

ðŸ“Œ à¦¨à¦¿à¦œà§‡à¦° problem à¦…à¦¨à§à¦¯à¦¾à¦¯à¦¼à§€ stopwords à¦¬à¦¾à¦¡à¦¼à¦¾à¦¨à§‹ à¦¯à¦¾à¦¯à¦¼à¥¤

---

## ðŸ”¸ Stopwords + Lemmatization (Mini Pipeline)

```python
from nltk.stem import WordNetLemmatizer

lemmatizer = WordNetLemmatizer()

filtered_lemmas = [
    lemmatizer.lemmatize(w)
    for w in filtered_words
]

print(filtered_lemmas)
```

### ðŸ“¤ Output

```
['child', 'running']
```

---

## ðŸ”š à¦¸à¦‚à¦•à§à¦·à§‡à¦ªà§‡ à¦®à¦¨à§‡ à¦°à¦¾à¦–à§à¦¨

* **Stopwords = low-meaning frequent words**
* à¦¸à¦¬ NLP task-à¦ remove à¦•à¦°à¦¾ à¦‰à¦šà¦¿à¦¤ à¦¨à¦¯à¦¼
* NLTK-à¦¤à§‡ built-in list à¦†à¦›à§‡
* Custom stopwords à¦¯à§‹à¦— à¦•à¦°à¦¾ à¦¯à¦¾à¦¯à¦¼

---

### ðŸ§  Exam-ready One-liner

> Stopwords are commonly used words that are removed during text preprocessing to reduce noise and improve model performance.

---
