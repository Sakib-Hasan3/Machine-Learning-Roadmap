---

# ЁЯФ╣ 03. Tokenisation and Basic Terminologies (NLP)

![Image](https://miro.medium.com/1%2AUhfwmhMN9sdfcWIbO5_tGg.jpeg)

![Image](https://miro.medium.com/1%2AN1YsdSJihlzJrvYBUDI-_A.jpeg)

![Image](https://miro.medium.com/1%2AVzhvZVKGVGynlsU0AZZQww.jpeg)

---

## ЁЯза Tokenisation ржХрзА?

**Tokenisation** рж╣рж▓рзЛ
ЁЯСЙ **ржПржХржЯрж┐ ржмрзЬ Text-ржХрзЗ ржЫрзЛржЯ ржЫрзЛржЯ ржЕржВрж╢рзЗ ржнрзЗржЩрзЗ ржлрзЗрж▓рж╛**,
ржпрзЗржЧрзБрж▓рзЛржХрзЗ ржмрж▓рж╛ рж╣рзЯ **Token**ред

рж╕рж╣ржЬ ржХржерж╛рзЯтАФ

> **Sentence тЖТ Word ржП ржнрж╛ржЧ ржХрж░рж╛ = Tokenisation**

---

## тЬВя╕П ржЙржжрж╛рж╣рж░ржг ржжрж┐рзЯрзЗ ржмрзЛржЭрж┐

### ЁЯФ╣ Sentence:

```
"I love Natural Language Processing"
```

### ЁЯФ╣ Tokenisation ржХрж░рж╛рж░ ржкрж░:

```
["I", "love", "Natural", "Language", "Processing"]
```

ржПржЦрж╛ржирзЗ ржкрзНрж░рждрж┐ржЯрж╛ рж╢ржмрзНржжржЗ ржПржХржЯрж┐ **Token**ред

---

## ЁЯзй Token ржХрзА?

ЁЯСЙ **Token = Text-ржПрж░ рж╕ржмржЪрзЗрзЯрзЗ ржЫрзЛржЯ meaningful unit**

Token рж╣рждрзЗ ржкрж╛рж░рзЗ:

* ржПржХржЯрж┐ word
* ржПржХржЯрж┐ number
* ржПржХржЯрж┐ punctuation
* ржПржоржиржХрж┐ ржПржХржЯрж┐ emoji ЁЯШД

---

## ЁЯзк Tokenisation-ржПрж░ ржкрзНрж░ржХрж╛рж░ржнрзЗржж

### 1я╕ПтГг Word Tokenisation

Sentence ржХрзЗ word-ржП ржнрж╛ржЩрж╛ред

**ржЙржжрж╛рж╣рж░ржг**

```
"Data Science is fun"
тЖТ ["Data", "Science", "is", "fun"]
```

---

### 2я╕ПтГг Sentence Tokenisation

Paragraph ржХрзЗ sentence-ржП ржнрж╛ржЩрж╛ред

**ржЙржжрж╛рж╣рж░ржг**

```
"I love NLP. It is very useful."
тЖТ ["I love NLP.", "It is very useful."]
```

---

### 3я╕ПтГг Character Tokenisation

Text ржХрзЗ character ржП ржнрж╛ржЩрж╛ред

**ржЙржжрж╛рж╣рж░ржг**

```
"NLP"
тЖТ ["N", "L", "P"]
```

ЁЯУМ рж╕рж╛ржзрж╛рж░ржгржд Deep Learning-ржП ржмрзНржпржмрж╣рж╛рж░ рж╣рзЯред

---

## ЁЯФд NLP-ржПрж░ Basic Terminologies (Must Know)

---

### ЁЯФ╣ 1. Corpus

ЁЯСЙ **Corpus = ржЕржирзЗржХржЧрзБрж▓рзЛ Text document-ржПрж░ collection**

**ржЙржжрж╛рж╣рж░ржг**

* рж╕ржм movie reviews ржПржХрж╕рж╛ржерзЗ
* рж╕ржм news article ржПржХрж╕рж╛ржерзЗ

---

### ЁЯФ╣ 2. Document

ЁЯСЙ **Document = Corpus-ржПрж░ ржПржХржЯрж┐ single text**

**ржЙржжрж╛рж╣рж░ржг**

* ржПржХржЯрж┐ news article
* ржПржХржЯрж┐ review

---

### ЁЯФ╣ 3. Vocabulary

ЁЯСЙ **Vocabulary = Corpus-ржПрж░ рж╕ржм unique word**

**ржЙржжрж╛рж╣рж░ржг**

```
Corpus = ["I love NLP", "I love ML"]
Vocabulary = ["I", "love", "NLP", "ML"]
```

---

### ЁЯФ╣ 4. Stop Words

ЁЯСЙ **Stop words = ржЦрзБржм common рж╢ржмрзНржж ржпрзЗржЧрзБрж▓рзЛ meaning ржХржо ржжрзЗрзЯ**

**ржЙржжрж╛рж╣рж░ржг**

* is
* am
* are
* the
* a
* an

ЁЯУМ NLP-рждрзЗ ржПржЧрзБрж▓рзЛ ржЕржирзЗржХ рж╕ржорзЯ remove ржХрж░рж╛ рж╣рзЯред

---

### ЁЯФ╣ 5. Stemming

ЁЯСЙ **Word-ржПрж░ root ржмрзЗрж░ ржХрж░рж╛ (ржнрж╛ржЩрж╛-ржнрж╛ржЩрж╛ root)**

**ржЙржжрж╛рж╣рж░ржг**

```
playing тЖТ play
played тЖТ play
```

ЁЯУМ Root рж╕ржмрж╕ржорзЯ correct word ржирж╛ржУ рж╣рждрзЗ ржкрж╛рж░рзЗред

---

### ЁЯФ╣ 6. Lemmatization

ЁЯСЙ **Grammatically correct root word ржмрзЗрж░ ржХрж░рж╛**

**ржЙржжрж╛рж╣рж░ржг**

```
better тЖТ good
running тЖТ run
```

ЁЯУМ Stemming-ржПрж░ ржЪрзЗрзЯрзЗ better ржХрж┐ржирзНрждрзБ slowред

---

### ЁЯФ╣ 7. Punctuation

ЁЯСЙ Comma, dot, ?, ! ржЗрждрзНржпрж╛ржжрж┐

NLP-рждрзЗ ржЕржирзЗржХ рж╕ржорзЯ remove ржХрж░рж╛ рж╣рзЯ:

```
Hello!!! тЖТ Hello
```

---

### ЁЯФ╣ 8. Lowercasing

ЁЯСЙ рж╕ржм text ржЫрзЛржЯ рж╣рж╛рждрзЗрж░ ржХрж░рж╛

```
"NLP Is FUN"
тЖТ "nlp is fun"
```

---

### ЁЯФ╣ 9. Noise

ЁЯСЙ Text-ржПрж░ unnecessary ржЕржВрж╢

**ржЙржжрж╛рж╣рж░ржг**

* URLs
* Emojis
* Special characters

---

## ЁЯФБ NLP Preprocessing Pipeline (рж╕рж╣ржЬ Flow)

![Image](https://media.licdn.com/dms/image/v2/D5612AQH-AcQSsJT7Wg/article-cover_image-shrink_720_1280/article-cover_image-shrink_720_1280/0/1722023278165?e=2147483647\&t=W9khkDqas5ZQKLvmpUEDf4hA8PB61BDpvfN1ahfcI-M\&v=beta)

![Image](https://miro.medium.com/1%2AVzhvZVKGVGynlsU0AZZQww.jpeg)

```
Raw Text
тЖУ
Lowercase
тЖУ
Tokenisation
тЖУ
Remove Stopwords
тЖУ
Stemming / Lemmatization
тЖУ
Clean Text
```

---

## ЁЯОп ржХрзЗржи Tokenisation ржПржд ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг?

ржХрж╛рж░ржгтАФ

* Computer text ржмрзБржЭрзЗ ржирж╛
* Token ржЫрж╛рзЬрж╛ ML ржХрж╛ржЬ ржХрж░рзЗ ржирж╛
* NLP-ржПрж░ рж╕ржм algorithm token-ржПрж░ ржЙржкрж░ ржХрж╛ржЬ ржХрж░рзЗ

ЁЯУМ **Tokenisation = NLP-ржПрж░ ржжрж░ржЬрж╛**

---

## ЁЯза One-Line Summary

> **Tokenisation рж╣рж▓рзЛ NLP-ржПрж░ ржкрзНрж░ржержо ржУ рж╕ржмржЪрзЗрзЯрзЗ ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг ржзрж╛ржк, ржпрзЗржЦрж╛ржирзЗ text-ржХрзЗ meaningful ржЫрзЛржЯ ржЕржВрж╢рзЗ ржнрж╛ржЩрж╛ рж╣рзЯред**

---

