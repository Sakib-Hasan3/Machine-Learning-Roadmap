---

# üß† Word2Vec ‚Äî Intuition (‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶Ø‡¶º)

## üî∑ Word2Vec ‡¶ï‡ßÄ?

**Word2Vec** ‡¶π‡¶≤‡ßã ‡¶è‡¶ï‡¶ü‡¶ø **neural-network based technique**
‡¶Ø‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶ú ‡¶π‡¶≤‡ßã:
üëâ **‡¶∂‡¶¨‡ßç‡¶¶‡¶ï‡ßá dense vector (embedding)** ‡¶è ‡¶∞‡ßÇ‡¶™‡¶æ‡¶®‡ßç‡¶§‡¶∞ ‡¶ï‡¶∞‡¶æ
üëâ ‡¶è‡¶Æ‡¶®‡¶≠‡¶æ‡¶¨‡ßá ‡¶Ø‡¶æ‡¶§‡ßá **‡¶è‡¶ï‡¶á ‡¶Ö‡¶∞‡ßç‡¶•‡ßá‡¶∞ ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶ï‡¶æ‡¶õ‡¶æ‡¶ï‡¶æ‡¶õ‡¶ø ‡¶•‡¶æ‡¶ï‡ßá**

üìå ‡¶è‡¶ü‡¶æ BoW ‡¶ó‡¶£‡¶®‡¶æ ‡¶ï‡¶∞‡ßá ‡¶®‡¶æ,
üìå ‡¶è‡¶ü‡¶æ ‡¶∂‡ßá‡¶ñ‡ßá **context ‡¶¶‡ßá‡¶ñ‡ßá**‡•§

---

## üß† Core Idea (‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶≤‡¶æ‡¶á‡¶®)

> **‚Äú‡¶Ø‡ßá ‡¶∂‡¶¨‡ßç‡¶¶‡¶ó‡ßÅ‡¶≤‡ßã ‡¶è‡¶ï‡¶á context-‡¶è ‡¶Ü‡¶∏‡ßá, ‡¶§‡¶æ‡¶¶‡ßá‡¶∞ ‡¶Ö‡¶∞‡ßç‡¶• ‡¶ï‡¶æ‡¶õ‡¶æ‡¶ï‡¶æ‡¶õ‡¶ø‚Äù**

‡¶è‡¶ü‡¶æ‡¶ï‡ßá‡¶á ‡¶¨‡¶≤‡ßá **Distributional Hypothesis**‡•§

---

## üî∑ Word2Vec ‡¶ï‡ßÄ‡¶≠‡¶æ‡¶¨‡ßá ‡¶∂‡ßá‡¶ñ‡ßá? (Big Picture)

Word2Vec:

* ‡¶è‡¶ï‡ßá ‡¶è‡¶ï‡ßá sentence ‡¶®‡ßá‡ßü
* ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∂‡¶¨‡ßç‡¶¶‡¶ï‡ßá ‡¶ï‡ßá‡¶®‡ßç‡¶¶‡ßç‡¶∞ ‡¶ï‡¶∞‡ßá
* ‡¶§‡¶æ‡¶∞ ‡¶Ü‡¶∂‡ßá‡¶™‡¶æ‡¶∂‡ßá‡¶∞ ‡¶∂‡¶¨‡ßç‡¶¶ **predict ‡¶ï‡¶∞‡¶§‡ßá ‡¶∂‡ßá‡¶ñ‡ßá**

‚û° Prediction ‡¶ï‡¶∞‡¶§‡ßá ‡¶ï‡¶∞‡¶§‡ßá
‚û° embedding ‡¶Ü‡¶™‡¶°‡ßá‡¶ü ‡¶π‡ßü
‚û° ‡¶∂‡ßá‡¶∑‡ßá embedding-‡¶è‡¶á ‡¶Ö‡¶∞‡ßç‡¶• ‡¶ß‡¶∞‡¶æ ‡¶™‡ßú‡ßá

---

# üî• Word2Vec-‡¶è‡¶∞ ‡¶¶‡ßÅ‡¶á‡¶ü‡¶æ Model

## 1Ô∏è‚É£ CBOW (Continuous Bag of Words)

## 2Ô∏è‚É£ Skip-gram

(‡¶è‡¶á ‡¶¶‡ßÅ‡¶ü‡ßã ‡¶™‡ßç‡¶∞‡¶æ‡ßü‡¶á exam-‡¶è ‡¶Ü‡¶∏‡ßá)

---

## üü¢ 1Ô∏è‚É£ CBOW ‚Äî Intuition

### ‚ùì CBOW ‡¶ï‡ßÄ ‡¶ï‡¶∞‡ßá?

üëâ **Context ‡¶¶‡ßá‡¶ñ‡ßá Center word predict ‡¶ï‡¶∞‡ßá**

---

### Example Sentence

```
I love machine learning
```

‡¶ß‡¶∞‡¶ø window size = 2

Context words:

```
I, love, learning
```

Target (predict ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶¨‡ßá):

```
machine
```

üìå ‡¶Æ‡¶æ‡¶®‡ßá:

> ‡¶Ü‡¶∂‡ßá‡¶™‡¶æ‡¶∂‡ßá‡¶∞ ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶¶‡ßá‡¶ñ‡ßá ‡¶Æ‡¶æ‡¶ù‡ßá‡¶∞ ‡¶∂‡¶¨‡ßç‡¶¶ guess ‡¶ï‡¶∞‡¶æ

---

### üß† CBOW ‡¶ï‡¶≤‡ßç‡¶™‡¶®‡¶æ

‡¶≠‡¶æ‡¶¨‡ßÅ‡¶®:

* ‡¶Ü‡¶∂‡ßá‡¶™‡¶æ‡¶∂‡ßá‡¶∞ ‡¶∂‡¶¨‡ßç‡¶¶ = clues
* ‡¶Æ‡¶æ‡¶ù‡ßá‡¶∞ ‡¶∂‡¶¨‡ßç‡¶¶ = answer

CBOW ‡¶¨‡¶≤‡ßá:

> ‚Äú‡¶è‡¶á ‡¶∂‡¶¨‡ßç‡¶¶‡¶ó‡ßÅ‡¶≤‡ßã ‡¶•‡¶æ‡¶ï‡¶≤‡ßá, ‡¶Æ‡¶æ‡¶ù‡¶ñ‡¶æ‡¶®‡ßá ‡¶ï‡ßÄ ‡¶•‡¶æ‡¶ï‡¶æ‡¶∞ ‡¶ï‡¶•‡¶æ?‚Äù

---

## üü° 2Ô∏è‚É£ Skip-gram ‚Äî Intuition

### ‚ùì Skip-gram ‡¶ï‡ßÄ ‡¶ï‡¶∞‡ßá?

üëâ **Center word ‡¶¶‡ßá‡¶ñ‡ßá Context words predict ‡¶ï‡¶∞‡ßá**

---

### Same Sentence

```
I love machine learning
```

Center word:

```
machine
```

Context words:

```
I, love, learning
```

üìå ‡¶Æ‡¶æ‡¶®‡ßá:

> ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶¶‡¶ø‡¶≤‡ßá, ‡¶§‡¶æ‡¶∞ ‡¶Ü‡¶∂‡ßá‡¶™‡¶æ‡¶∂‡ßá ‡¶ï‡ßÄ ‡¶ï‡ßÄ ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶Ü‡¶∏‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá

---

### üß† Skip-gram ‡¶ï‡¶≤‡ßç‡¶™‡¶®‡¶æ

‡¶≠‡¶æ‡¶¨‡ßÅ‡¶®:

* Center word = hint
* Model ‡¶¨‡¶≤‡ßá:

> ‚Äú‡¶è‡¶á ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶è‡¶≤‡ßá, ‡¶Ü‡¶∂‡ßá‡¶™‡¶æ‡¶∂‡ßá ‡¶ï‡ßÄ ‡¶ï‡ßÄ ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶Ü‡¶∏‡¶æ‡¶∞ ‡¶∏‡¶Æ‡ßç‡¶≠‡¶æ‡¶¨‡¶®‡¶æ?‚Äù

---

# üîÑ CBOW vs Skip-gram (Exam Table)

| ‡¶¨‡¶ø‡¶∑‡ßü       | CBOW           | Skip-gram      |
| ---------- | -------------- | -------------- |
| Prediction | Context ‚Üí Word | Word ‚Üí Context |
| Speed      | Fast           | Slower         |
| Rare words | ‡¶¶‡ßÅ‡¶∞‡ßç‡¶¨‡¶≤         | ‡¶≠‡¶æ‡¶≤‡ßã           |
| Small data | ‡¶≠‡¶æ‡¶≤‡ßã           | ‡¶≠‡¶æ‡¶≤‡ßã           |
| Large data | ‡¶≠‡¶æ‡¶≤‡ßã           | ‡¶ñ‡ßÅ‡¶¨ ‡¶≠‡¶æ‡¶≤‡ßã       |

---

## üî∑ Training ‡¶ö‡¶≤‡¶æ‡¶ï‡¶æ‡¶≤‡ßÄ‡¶® ‡¶ï‡ßÄ ‡¶π‡ßü?

* ‡¶∂‡ßÅ‡¶∞‡ßÅ‡¶§‡ßá embeddings random
* Prediction ‡¶≠‡ßÅ‡¶≤ ‡¶π‡ßü
* Error backpropagation
* Embeddings update ‡¶π‡ßü

üìå ‡¶Ö‡¶®‡ßá‡¶ï iteration ‡¶™‡¶∞‡ßá:

> ‡¶Ö‡¶∞‡ßç‡¶•‡¶ó‡¶§ ‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï embedding-‡¶è ‡¶ú‡¶Æ‡¶æ ‡¶π‡ßü

---

## üî• Famous Result (Exam Gold ‚≠ê)

Word2Vec ‡¶∂‡ßá‡¶ñ‡ßá:

```
king ‚àí man + woman ‚âà queen
```

‡¶ï‡¶æ‡¶∞‡¶£:

* ‚Äúking‚Äù ‡¶ì ‚Äúqueen‚Äù ‡¶è‡¶ï‡¶á context-‡¶è ‡¶Ü‡¶∏‡ßá
* gender difference ‡¶è‡¶ï‡¶ü‡¶æ direction-‡¶è encode ‡¶π‡ßü

---

## üß† Word2Vec ‡¶ï‡ßá‡¶® BoW ‡¶•‡ßá‡¶ï‡ßá ‡¶≠‡¶æ‡¶≤‡ßã?

| BoW         | Word2Vec      |
| ----------- | ------------- |
| ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶ó‡ßã‡¶®‡ßá   | context ‡¶¶‡ßá‡¶ñ‡ßá  |
| Sparse      | Dense         |
| Meaning ‡¶®‡ßá‡¶á | Meaning ‡¶Ü‡¶õ‡ßá   |
| Order ‡¶®‡ßá‡¶á   | Context aware |

---

## ‚úçÔ∏è Exam-Ready Definition

> **Word2Vec** ‡¶π‡¶≤‡ßã ‡¶è‡¶ï‡¶ü‡¶ø neural network ‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø‡¶ï embedding technique ‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá ‡¶∂‡¶¨‡ßç‡¶¶‡¶ï‡ßá ‡¶è‡¶Æ‡¶® ‡¶≠‡ßá‡¶ï‡ßç‡¶ü‡¶∞‡ßá ‡¶∞‡ßÇ‡¶™‡¶æ‡¶®‡ßç‡¶§‡¶∞ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º ‡¶Ø‡¶æ‡¶§‡ßá ‡¶è‡¶ï‡¶á context-‡¶è ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡ßÉ‡¶§ ‡¶∂‡¶¨‡ßç‡¶¶‡¶ó‡ßÅ‡¶≤‡ßã ‡¶≠‡ßá‡¶ï‡ßç‡¶ü‡¶∞ ‡¶∏‡ßç‡¶™‡ßá‡¶∏‡ßá ‡¶ï‡¶æ‡¶õ‡¶æ‡¶ï‡¶æ‡¶õ‡¶ø ‡¶Ö‡¶¨‡¶∏‡ßç‡¶•‡¶æ‡¶® ‡¶ï‡¶∞‡ßá‡•§

---

## üß† ‡¶Æ‡¶®‡ßá ‡¶∞‡¶æ‡¶ñ‡¶æ‡¶∞ ‡¶ü‡ßç‡¶∞‡¶ø‡¶ï

> **‚ÄúBoW ‡¶ó‡ßã‡¶®‡ßá,
> Word2Vec ‡¶∂‡ßá‡¶ñ‡ßá‚Äù**

---

## ‚ùì ‡¶ï‡¶ñ‡¶® Word2Vec ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßã?

* Semantic similarity ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞
* Medium‚Äìlarge dataset
* Classical deep NLP (pre-BERT era)

‚ùå ‡¶ñ‡ßÅ‡¶¨ ‡¶õ‡ßã‡¶ü corpus ‡¶π‡¶≤‡ßá ‡¶≠‡¶æ‡¶≤‡ßã ‡¶∂‡ßá‡¶ñ‡ßá ‡¶®‡¶æ

---


