---

# ЁЯФв Word Embeddings тАФ Numerical Example (Exam Style)

## ЁЯУШ Given (ржзрж░рж╛ ржпрж╛ржХ)

ржЖржорж╛ржжрзЗрж░ ржХрж╛ржЫрзЗ ржЦрзБржм ржЫрзЛржЯ ржПржХржЯрж┐ embedding space ржЖржЫрзЗ (2-D рж╢рзБржзрзБ ржмрзЛржЭрж╛рж░ ржЬржирзНржп)ред

ржзрж░рж╛ ржпрж╛ржХ ржирж┐ржЪрзЗрж░ **pre-trained embeddings** ржжрзЗржУрзЯрж╛ ржЖржЫрзЗ:

| Word  | Embedding Vector |
| ----- | ---------------- |
| king  | (2.0, 3.0)       |
| queen | (2.2, 3.1)       |
| man   | (1.0, 1.0)       |
| woman | (1.2, 1.1)       |

ЁЯУМ ржмрж╛рж╕рзНрждржмрзЗ dimension 100тАУ300 рж╣рзЯ, ржХрж┐ржирзНрждрзБ **exam ржмрзЛржЭрж╛ржирзЛрж░ ржЬржирзНржп 2-D** ржзрж░рж╛ рж╣рзЯред

---

## ЁЯФ╖ Example 1: Similarity ржмрзЛржЭрж╛ (Cosine Similarity)

### тЭУ Question

**king** ржПржмржВ **queen** ржХрж┐ ржЕрж░рзНржерзЗ ржХрж╛ржЫрж╛ржХрж╛ржЫрж┐?

---

### Step 1я╕ПтГг: Cosine Similarity Formula

[
\cos(\theta) = \frac{\vec{A}\cdot\vec{B}}{|\vec{A}||\vec{B}|}
]

---

### Step 2я╕ПтГг: Dot Product

[
king \cdot queen = (2.0├Ч2.2) + (3.0├Ч3.1)
]

[
= 4.4 + 9.3 = 13.7
]

---

### Step 3я╕ПтГг: Magnitude

[
|king| = \sqrt{2^2 + 3^2} = \sqrt{13} \approx 3.61
]

[
|queen| = \sqrt{2.2^2 + 3.1^2} = \sqrt{14.45} \approx 3.80
]

---

### Step 4я╕ПтГг: Cosine Similarity

[
\cos(\theta) = \frac{13.7}{3.61 ├Ч 3.80} \approx 0.998
]

тЬФ **ржЦрзБржм ржХрж╛ржЫрж╛ржХрж╛ржЫрж┐ (тЙИ1)**
тЮб ржЕрж░рзНржерзЗ ржЦрзБржм similar

---

## ЁЯФ╖ Example 2: Famous Embedding Arithmetic (Exam Gold тнР)

### тЭУ Question

ржкрзНрж░ржорж╛ржг ржХрж░рзЛ:
[
king тИТ man + woman тЙИ queen
]

---

### Step 1я╕ПтГг: Vector Subtraction

```
king тИТ man
= (2.0, 3.0) тИТ (1.0, 1.0)
= (1.0, 2.0)
```

---

### Step 2я╕ПтГг: Add woman

```
(1.0, 2.0) + (1.2, 1.1)
= (2.2, 3.1)
```

---

### Step 3я╕ПтГг: Compare

```
queen = (2.2, 3.1)
```

тЬФ Exact match ЁЯОп

тЮб **Embedding semantic relationship ржзрж░рзЗ**

---

## ЁЯФ╖ Example 3: Sentence Embedding (Simple Average)

ржзрж░рж╛ ржпрж╛ржХ embeddings:

| Word | Vector     |
| ---- | ---------- |
| I    | (0.1, 0.2) |
| love | (0.8, 0.9) |
| NLP  | (1.0, 1.1) |

Sentence:

```
"I love NLP"
```

---

### Step 1я╕ПтГг: Average Embedding

[
\frac{(0.1,0.2) + (0.8,0.9) + (1.0,1.1)}{3}
]

[
= \frac{(1.9, 2.2)}{3}
= (0.63, 0.73)
]

тЬФ ржПржЯрж┐ржЗ **sentence embedding**

---

## ЁЯФ╖ Compare with BoW (Numerical Contrast)

### BoW Vector (Vocabulary = [I, love, NLP])

```
[1, 1, 1]
```

тЭМ ржХрзЛржирзЛ ржЕрж░рзНрже ржирзЗржЗ
тЭМ similarity weak

### Embedding Vector

```
[0.63, 0.73]
```

тЬФ ржЕрж░рзНржержмрж╣
тЬФ similarity ржЧржгржирж╛ meaningful

---

## тЬНя╕П Exam-Ready Short Answer

> Word embedding numerical example-ржП ржкрзНрж░рждрж┐ржЯрж┐ рж╢ржмрзНржж ржПржХржЯрж┐ dense vector ржжрзНржмрж╛рж░рж╛ ржкрзНрж░ржХрж╛рж╢рж┐ржд рж╣ржпрж╝ ржПржмржВ cosine similarity ржмрж╛ vector arithmetic ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ рж╢ржмрзНржжрзЗрж░ semantic рж╕ржорзНржкрж░рзНржХ ржирж┐рж░рзНржгржпрж╝ ржХрж░рж╛ ржпрж╛ржпрж╝ред

---

## ЁЯза ржоржирзЗ рж░рж╛ржЦрж╛рж░ ржЯрзНрж░рж┐ржХ

> **тАЬBoW ржЧрзЛржирзЗ,
> Embedding рж╣рж┐рж╕рж╛ржм ржХрж░рзЗ рж╕ржорзНржкрж░рзНржХтАЭ**

---
